{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9b6ebe3",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import pprint\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "from krippendorff import alpha\n",
    "from statsmodels.stats.inter_rater import fleiss_kappa, aggregate_raters, cohens_kappa, to_table\n",
    "from irrCAC.raw import CAC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bf22497",
   "metadata": {},
   "source": [
    "#### Create Variables and Load Dialogues from JSON + Batch IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3863ab6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "mwoz_judge_json = \"results/judge_results_mwoz_autotod/20250403_025805/mwoz-autotod-gpt-4o_j.json\"\n",
    "tau_air_judge_json = \"results/judge-results-tau/20250131_152503-tau-4o-airline/tau-gpt-4o_j.json\"\n",
    "tau_retail_judge_json = \"results/judge-results-tau/20250131_152422-tau-4o-retail/tau-gpt-4o_j.json\"\n",
    "human_eval_batch_dir = \"datasets/main_human_eval\"\n",
    "\n",
    "# load dialogues: order mwoz, tau-retail, tau-airline\n",
    "with open(mwoz_judge_json, 'r') as f:\n",
    "\t\tmwoz_judge = json.load(f)\n",
    "mwoz_dials = mwoz_judge.get('dialogues', [])\n",
    "with open(tau_retail_judge_json, 'r') as f:\n",
    "\t\ttau_retail_judge = json.load(f)\n",
    "tau_retail_dials = tau_retail_judge['dialogues']\n",
    "with open(tau_air_judge_json, 'r') as f:\n",
    "\t\ttau_air_judge = json.load(f)\n",
    "tau_air_dials = tau_air_judge['dialogues']\n",
    "# load batches\n",
    "num_batches = 10\n",
    "batch_list = {}\n",
    "batch_order = {}\n",
    "for ind in range(1, num_batches + 1):\n",
    "\twith open(f\"{human_eval_batch_dir}/batch{ind}.json\", 'r') as f:\n",
    "\t\tcurr_batch_list = json.load(f)\n",
    "\tif curr_batch_list is None or len(curr_batch_list) == 0:\n",
    "\t\tprint('No batches found at this path:',  ind)\n",
    "\t\texit()\n",
    "\t# add batches to full list\n",
    "\tbatch_list[ind] = {}\n",
    "\tif \"autotod_mwoz\" not in batch_list:\n",
    "\t\tbatch_list[ind][\"autotod_mwoz\"] = curr_batch_list[\"autotod_mwoz\"]\n",
    "\telse:\n",
    "\t\tbatch_list[ind][\"autotod_mwoz\"].extend(curr_batch_list[\"autotod_mwoz\"])\n",
    "\tif \"tau\" not in batch_list:\n",
    "\t\tbatch_list[ind][\"tau\"] = curr_batch_list[\"tau\"]\n",
    "\telse:\n",
    "\t\tbatch_list[ind][\"tau\"][\"retail\"].extend(curr_batch_list[\"tau\"][\"retail\"])\n",
    "\t\tbatch_list[ind][\"tau\"][\"airline\"].extend(curr_batch_list[\"tau\"][\"airline\"])\n",
    "\tbatch_order[ind] = curr_batch_list[\"order\"]\n",
    "\n",
    "pprint.pprint(batch_list, compact=True)\n",
    "pprint.pprint(batch_order, compact=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3c1ca84",
   "metadata": {},
   "source": [
    "#### Compile Relevant Dialogues From Batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef30fc81",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def get_batch_dialogues(\n",
    "\tmwoz_dialogues: dict, \n",
    "\ttau_air_dialogues: dict, \n",
    "\ttau_retail_dialogues: dict, \n",
    "\tbatch_list: dict\n",
    ") -> dict:\n",
    "\t#load dialogues\n",
    "\tbatch_dials = []\n",
    "\tmwoz_batch_ids = batch_list[\"autotod_mwoz\"]\n",
    "\ttau_air_batch_ids = batch_list[\"tau\"][\"airline\"]\n",
    "\ttau_retail_batch_ids = batch_list[\"tau\"][\"retail\"]\n",
    "\t# load batch (order: mwoz, tau-retail, tau-airline)\n",
    "\tfor batch_id in mwoz_batch_ids:\n",
    "\t\tfor id, dial in mwoz_dialogues.items():\n",
    "\t\t\tif id.split(\".json\")[0].lower() == batch_id:\n",
    "\t\t\t\tbatch_dials.append(dial)\n",
    "\t\t\t\tbreak\n",
    "\tfor batch_id in tau_retail_batch_ids:\n",
    "\t\tfor id, dial in tau_retail_dialogues.items():\n",
    "\t\t\tif id == batch_id:\n",
    "\t\t\t\tbatch_dials.append(dial)\n",
    "\t\t\t\tbreak\n",
    "\tfor batch_id in tau_air_batch_ids:\n",
    "\t\tfor id, dial in tau_air_dialogues.items():\n",
    "\t\t\tif id == batch_id:\n",
    "\t\t\t\tbatch_dials.append(dial)\n",
    "\t\t\t\tbreak\n",
    "\ttot_batch_len = len(mwoz_batch_ids) + len(tau_air_batch_ids) + len(tau_retail_batch_ids)\n",
    "\tif len(batch_dials) != tot_batch_len:\n",
    "\t\tprint(\"filtered dials size does not match batches:\", len(batch_dials), tot_batch_len)\n",
    "\t\texit()\n",
    "\treturn batch_dials\n",
    "\n",
    "# get batch dialogues for all eval batches\n",
    "batch_dials = {}\n",
    "for b_ind, b_list in batch_list.items():\n",
    "\tdials = get_batch_dialogues(\n",
    "\t\tmwoz_dials, \n",
    "\t\ttau_air_dials, \n",
    "\t\ttau_retail_dials, \n",
    "\t\tb_list\n",
    "\t)\n",
    "\tbatch_dials[b_ind] = dials\n",
    "\n",
    "# pprint.pprint(batch_dials, compact=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fdc30aa",
   "metadata": {},
   "source": [
    "#### Extract Qualtrics Human Eval CSV Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ead322eb",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def extract_human_csv_data(\n",
    "\thuman_eval_csv: dict, \n",
    "\tbatch_dialogues: dict, \n",
    "\tbatch_order: dict\n",
    ") -> dict:\n",
    "\t\"\"\"Read CSV data and convert to appropriate format\"\"\"\n",
    "\tdims = ['conv_consistency', 'backend_consistency', 'policy_completeness']\n",
    "\tinput_csv = human_eval_csv[\"csv_file\"]\n",
    "\teval_csv = pd.read_csv(input_csv, on_bad_lines='warn') \n",
    "\tstart_col = human_eval_csv['start_col']\n",
    "\tend_col = human_eval_csv['end_col']\n",
    "\tsearch_str = '2025'\n",
    "\tturn_result = {}\n",
    "\tdial_result = {}\n",
    "\tfirst_eval_row = eval_csv.StartDate.str.contains(search_str).idxmax()\n",
    "\thuman_scores = eval_csv.loc[first_eval_row:, start_col:end_col].to_numpy()\n",
    "\tmapping = {\n",
    "\t\t\"Very Good\": 5.0, \n",
    "\t\t\"Good\": 4.0, \n",
    "\t\t\"Fair\": 3.0, \n",
    "\t\t\"Bad\": 2.0, \n",
    "\t\t\"Very Bad\": 1.0\n",
    "\t}\n",
    "\t# mapping = {\n",
    "\t# \t\"Very Good\": 3.0, \n",
    "\t# \t\"Good\": 3.0, \n",
    "\t# \t\"Fair\": 2.0, \n",
    "\t# \t\"Bad\": 1.0, \n",
    "\t# \t\"Very Bad\": 1.0\n",
    "\t# }\n",
    "\tvectorized_map = np.vectorize(lambda x: mapping[x.strip()])\n",
    "\tint_scores = vectorized_map(human_scores)\n",
    "\t# extract scores into results dialogue map\n",
    "\tscores_idx = 0\n",
    "\tfor i, dial in enumerate(batch_dialogues):\n",
    "\t\tif batch_order[i][\"type\"] == \"tau_retail\":\n",
    "\t\t\tdial_id = f\"retail_{batch_order[i]['id']}\"\n",
    "\t\telif batch_order[i][\"type\"] == \"tau_airline\":\n",
    "\t\t\tdial_id = f\"airline_{batch_order[i]['id']}\"\n",
    "\t\telse:\n",
    "\t\t\tdial_id = batch_order[i][\"id\"]\n",
    "\t\tturn_result[dial_id] = {}\n",
    "\t\t# add turn scores\n",
    "\t\tfor _ in dial:\n",
    "\t\t\tfor i, metric in enumerate(dims):\n",
    "\t\t\t\tif metric not in turn_result[dial_id]:\n",
    "\t\t\t\t\tturn_result[dial_id][metric] = int_scores[:,scores_idx+i]\n",
    "\t\t\t\telse:\n",
    "\t\t\t\t\tturn_result[dial_id][metric] = np.concat(\n",
    "\t\t\t\t\t\t(turn_result[dial_id][metric], int_scores[:,scores_idx+i])\n",
    "\t\t\t\t\t)\n",
    "\t\t\t\t# turn_result[dial_id].append({\n",
    "\t\t\t\t# \t'conv_consistency': int_scores[:,scores_idx],\n",
    "\t\t\t\t# \t'backend_consistency': int_scores[:,scores_idx+1],\n",
    "\t\t\t\t# \t'policy_completeness': int_scores[:, scores_idx+2]\n",
    "\t\t\t\t# })\n",
    "\t\t\tscores_idx += 3\n",
    "\t\t# add dial scores\n",
    "\t\tdial_result[dial_id] = {\n",
    "\t\t\t\t'conv_consistency': int_scores[:,scores_idx],\n",
    "\t\t\t\t'backend_consistency': int_scores[:,scores_idx+1],\n",
    "\t\t\t\t'policy_completeness': int_scores[:, scores_idx+2]\n",
    "\t\t}\n",
    "\t\tscores_idx += 3\n",
    "\treturn turn_result, dial_result\n",
    "\n",
    "human_eval_csv = {\n",
    "\t1: { \n",
    "\t\t\"csv_file\": \"qualtrics/results/main_human_eval/eval_1.csv\", \n",
    "\t\t\"start_col\": \"QID3_1\", \n",
    "\t\t\"end_col\": \"QID187_3\" \n",
    "\t},\n",
    "\t2: { \n",
    "\t\t\"csv_file\": \"qualtrics/results/main_human_eval/eval_2.csv\", \n",
    "\t\t\"start_col\": \"QID3_1\", \n",
    "\t\t\"end_col\": \"QID135_3\" \n",
    "\t},\n",
    "\t3: { \n",
    "\t\t\"csv_file\": \"qualtrics/results/main_human_eval/eval_3.csv\", \n",
    "\t\t\"start_col\": \"QID3_1\", \n",
    "\t\t\"end_col\": \"QID180_3\" \n",
    "\t},\n",
    "\t4: { \n",
    "\t\t\"csv_file\": \"qualtrics/results/main_human_eval/eval_4.csv\", \n",
    "\t\t\"start_col\": \"QID3_1\", \n",
    "\t\t\"end_col\": \"QID123_3\" \n",
    "\t},\n",
    "\t5: { \n",
    "\t\t\"csv_file\": \"qualtrics/results/main_human_eval/eval_5.csv\", \n",
    "\t\t\"start_col\": \"QID3_1\", \n",
    "\t\t\"end_col\": \"QID129_3\" \n",
    "\t},\n",
    "\t6: {\n",
    "\t\t\"csv_file\": \"qualtrics/results/main_human_eval/eval_6.csv\", \n",
    "\t\t\"start_col\": \"QID3_1\", \n",
    "\t\t\"end_col\": \"QID341_3\" \n",
    "\t},\n",
    "\t7: { \n",
    "\t\t\"csv_file\": \"qualtrics/results/main_human_eval/eval_7.csv\", \n",
    "\t\t\"start_col\": \"QID3_1\", \n",
    "\t\t\"end_col\": \"QID137_3\" \n",
    "\t},\n",
    "\t8: {\n",
    "\t\t\"csv_file\": \"qualtrics/results/main_human_eval/eval_8.csv\", \n",
    "\t\t\"start_col\": \"QID3_1\", \n",
    "\t\t\"end_col\": \"QID142_3\" \n",
    "\t},\n",
    "\t9: { \n",
    "\t\t\"csv_file\": \"qualtrics/results/main_human_eval/eval_9.csv\", \n",
    "\t\t\"start_col\": \"QID3_1\", \n",
    "\t\t\"end_col\": \"QID115_3\" \n",
    "\t}\n",
    "}\n",
    "\n",
    "human_batch_scores = {}\n",
    "for i in batch_dials.keys():\n",
    "\tif i not in human_eval_csv:\n",
    "\t\tcontinue\n",
    "\tturn_eval_data, dial_eval_data = extract_human_csv_data(\n",
    "\t\thuman_eval_csv[i], \n",
    "\t\tbatch_dials[i], \n",
    "\t\tbatch_order[i]\n",
    "\t)\n",
    "\thuman_batch_scores[i] = { \n",
    "\t\t\"turn_level\": turn_eval_data, \n",
    "\t\t\"dial_level\": dial_eval_data\n",
    "\t}\n",
    "\n",
    "pprint.pprint(human_batch_scores, compact=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ee577cc",
   "metadata": {},
   "source": [
    "#### Extract TD-Eval Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8782425",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Compare human evaluation data with LLM evaluation data\"\"\"    \n",
    "def extract_score(score_str: str) -> int:\n",
    "\ttry:\n",
    "\t\t# regex matching\n",
    "\t\tmatch = re.search(r'Score: (\\d+)', str(score_str))\n",
    "\t\tif not match:\n",
    "\t\t\tprint(\"Score not found in string:\",score_str)\n",
    "\t\t\tprint(\"Checking substring\")\n",
    "\t\t\t# check substring\n",
    "\t\t\tif \"Very Good\" in score_str:\n",
    "\t\t\t\treturn 5\n",
    "\t\t\telif \"Good\" in score_str:\n",
    "\t\t\t\treturn 4\n",
    "\t\t\telif \"Fair\" in score_str:\n",
    "\t\t\t\treturn 3\n",
    "\t\t\t# check more detailed string first\n",
    "\t\t\telif \"Bad\" in score_str:\n",
    "\t\t\t\treturn 2\n",
    "\t\t\telif \"Very Bad\" in score_str: \n",
    "\t\t\t\treturn 1\n",
    "\t\t\telse:\n",
    "\t\t\t\tprint(\"Score still not found with substring check\")\n",
    "\t\t\t\treturn 5\n",
    "\t\treturn int(match.group(1)) if match else 5\n",
    "\texcept:\n",
    "\t\tprint(\"Score not found in string:\",score_str)\n",
    "\t\treturn 5\n",
    "\n",
    "def extract_tdeval_scores(\n",
    "\tbatch_dialogues: list, \n",
    "\tautotod_dial_level: dict,\n",
    "\ttau_retail_dial_level: dict,\n",
    "\ttau_airline_dial_level: dict,\n",
    "\tbatch_order: dict\n",
    ") -> tuple:\n",
    "\tdims = ['conv_consistency', 'backend_consistency', 'policy_completeness']\n",
    "\tturn_scores = {}\n",
    "\tdial_scores = {}\n",
    "\tfor idx, batch_dial in enumerate(batch_order):\n",
    "\t\t# convert batch dial id format\n",
    "\t\tbatch_dial_id = batch_dial[\"id\"]\n",
    "\t\tif batch_dial['type'] == \"tau_retail\":\n",
    "\t\t\tbatch_dial_id = f\"retail_{batch_dial_id}\"\n",
    "\t\telif batch_dial['type'] == \"tau_airline\":\n",
    "\t\t\tbatch_dial_id = f\"airline_{batch_dial_id}\"\n",
    "\t\tllm_dial = batch_dialogues[idx]\n",
    "\t\t# extract scores from td-eval json data\n",
    "\t\tturn_scores[batch_dial_id] = {}\n",
    "\t\tfor turn_idx, turn in enumerate(llm_dial):    \n",
    "\t\t\tturn_score = turn[\"scores\"]\n",
    "\t\t\t# skip turn score if any negative/invalid scores exist\n",
    "\t\t\tall_scores = np.array([\n",
    "\t\t\t\textract_score(turn_score['conv_consistency'][\"score\"]), \n",
    "\t\t\t\textract_score(turn_score['backend_consistency'][\"score\"]), \n",
    "\t\t\t\textract_score(turn_score['policy_completeness'][\"score\"])\n",
    "\t\t\t])\n",
    "\t\t\tif np.any(all_scores <= 0):\n",
    "\t\t\t\tprint(\"missing a score\")\n",
    "\t\t\t\tcontinue\n",
    "\t\t\t# Get LLM scores\n",
    "\t\t\tfor metric in dims:\n",
    "\t\t\t\tif metric not in turn_scores[batch_dial_id]:\n",
    "\t\t\t\t\tturn_scores[batch_dial_id][metric] = [\n",
    "\t\t\t\t\t\textract_score(turn_score[metric][\"score\"])\n",
    "\t\t\t\t\t]\n",
    "\t\t\t\telse:\n",
    "\t\t\t\t\tturn_scores[batch_dial_id][metric].append(\n",
    "\t\t\t\t\t\textract_score(turn_score[metric][\"score\"])\n",
    "\t\t\t\t\t)\n",
    "\t\t# get dialogue level score\n",
    "\t\tdial_scores[batch_dial_id] = {}\n",
    "\t\t# grab from TD-Eval \n",
    "\t\tfor metric in dims:\n",
    "\t\t\tif batch_dial['type'] == \"autotod_mwoz\":\n",
    "\t\t\t\torig_dial_id = f\"{batch_dial_id.upper()}.json\"\n",
    "\t\t\t\tscore = extract_score(autotod_dial_level[orig_dial_id][metric][\"score\"])\n",
    "\t\t\telif batch_dial['type'] == \"tau_retail\":  \n",
    "\t\t\t\torig_dial_id = batch_dial_id.replace(\"retail_\", \"\")\n",
    "\t\t\t\tscore = extract_score(\n",
    "\t\t\t\t\ttau_retail_dial_level[orig_dial_id][metric][\"score\"]\n",
    "\t\t\t\t)\n",
    "\t\t\telif batch_dial['type'] == \"tau_airline\":\n",
    "\t\t\t\torig_dial_id = batch_dial_id.replace(\"airline_\", \"\")\n",
    "\t\t\t\tscore = extract_score(\n",
    "\t\t\t\t\ttau_airline_dial_level[orig_dial_id][metric][\"score\"]\n",
    "\t\t\t\t)\n",
    "\t\t\tdial_scores[batch_dial_id][metric] = score\n",
    "\t\t\n",
    "\treturn turn_scores, dial_scores\n",
    "\n",
    "autotod_dial_level_path = \"results/dial_level_results/autotod/mwoz-dial-level-gpt-4o_j.json\"\n",
    "with open(autotod_dial_level_path, 'r') as f:\n",
    "\tautotod_dial_level_data = json.load(f)\n",
    "autotod_dial_level = autotod_dial_level_data[\"dialogues\"]\n",
    "tau_retail_dial_level_path = \"results/dial_level_results/tau/retail-dial-level-gpt-4o_j.json\"\n",
    "with open(tau_retail_dial_level_path, 'r') as f:\n",
    "\ttau_retail_dial_level_data = json.load(f)\n",
    "tau_retail_dial_level = tau_retail_dial_level_data[\"dialogues\"]\n",
    "tau_airline_dial_level_path = \"results/dial_level_results/tau/airline-dial-level-gpt-4o_j.json\"\n",
    "with open(tau_airline_dial_level_path, 'r') as f:\n",
    "\ttau_airline_dial_level_data = json.load(f)\n",
    "tau_airline_dial_level = tau_airline_dial_level_data[\"dialogues\"]\n",
    "\n",
    "tdeval_batch_scores = {}\n",
    "for i in batch_dials.keys():\n",
    "\tif i not in human_eval_csv:\n",
    "\t\tcontinue\n",
    "\tturn_scores, dial_scores = extract_tdeval_scores(\n",
    "\t\tbatch_dials[i], \n",
    "\t\tautotod_dial_level,\n",
    "\t\ttau_retail_dial_level,\n",
    "\t\ttau_airline_dial_level,\n",
    "\t\tbatch_order[i]\n",
    "\t)\n",
    "\ttdeval_batch_scores[i] = {\n",
    "\t\t\"turn_level\": turn_scores, \n",
    "\t\t\"dial_level\": dial_scores \n",
    "\t}\n",
    "pprint.pprint(tdeval_batch_scores, compact=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d72b9a4",
   "metadata": {},
   "source": [
    "#### Extract LMUnit Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b98af45f",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def extract_lmunit_scores(\n",
    "\tautotod_lmunit_dials: dict, \n",
    "\ttau_lmunit_dials: dict, \n",
    "\tlmunit_dial_level: dict,\n",
    "\tbatch_order: dict\n",
    "):\n",
    "\t# bundle lmunit scores by batch and id\n",
    "\tdims = ['conv_consistency', 'backend_consistency', 'policy_completeness']\n",
    "\tturn_scores = {}\n",
    "\tdial_scores = {}\n",
    "\tfor batch_dial in batch_order:\n",
    "\t\t# convert batch dial id format\n",
    "\t\tbatch_dial_id = batch_dial[\"id\"]\n",
    "\t\tif batch_dial[\"type\"] == \"autotod_mwoz\":\n",
    "\t\t\tprev_autotod_id = f\"{batch_dial_id.upper()}.json\"\n",
    "\t\t\tllm_dial = autotod_lmunit_dials[prev_autotod_id]\n",
    "\t\telif batch_dial['type'] == \"tau_retail\":\n",
    "\t\t\tbatch_dial_id = f\"retail_{batch_dial_id}\"\n",
    "\t\t\tllm_dial = tau_lmunit_dials[batch_dial_id]\n",
    "\t\telif batch_dial['type'] == \"tau_airline\":\n",
    "\t\t\tbatch_dial_id = f\"airline_{batch_dial_id}\"\n",
    "\t\t\tllm_dial = tau_lmunit_dials[batch_dial_id]\n",
    "\t\t# extract scores from lmunit json data\n",
    "\t\tturn_scores[batch_dial_id] = {}\n",
    "\t\tfor turn_idx, turn in enumerate(llm_dial):    \n",
    "\t\t\tturn_score = turn[\"scores\"]\n",
    "\t\t\t# skip turn score if any negative/invalid scores exist\n",
    "\t\t\tall_scores = np.array([\n",
    "\t\t\t\tturn_score['conv_consistency'][\"score\"], \n",
    "\t\t\t\tturn_score['backend_consistency'][\"score\"], \n",
    "\t\t\t\tturn_score['policy_completeness'][\"score\"]\n",
    "\t\t\t])\n",
    "\t\t\tif np.any(all_scores <= 0):\n",
    "\t\t\t\tprint(\"missing a score\")\n",
    "\t\t\t\tcontinue\n",
    "\t\t\t# Get LLM scores\n",
    "\t\t\tfor metric in dims:\n",
    "\t\t\t\tif metric not in turn_scores[batch_dial_id]:\n",
    "\t\t\t\t\tturn_scores[batch_dial_id][metric] = [\n",
    "\t\t\t\t\t\tturn_score[metric][\"score\"]\n",
    "\t\t\t\t\t]\n",
    "\t\t\t\telse:\n",
    "\t\t\t\t\tturn_scores[batch_dial_id][metric].append(\n",
    "\t\t\t\t\t\tturn_score[metric][\"score\"]\n",
    "\t\t\t\t\t)\n",
    "\t\t# get dialogue level score\n",
    "\t\tdial_scores[batch_dial_id] = lmunit_dial_level[batch_dial_id]\n",
    "\n",
    "\treturn turn_scores, dial_scores\n",
    "\n",
    "autotod_lmunit_path = \"results/judge_results_lmunit/autotod/mwoz-autotod-lmunit_j.json\"\n",
    "tau_lmunit_path = \"results/judge_results_lmunit/tau/lmunit_scores.json\"\n",
    "lmunit_dial_level_path = \"results/dial_level_results/lmunit/lmunit_dial_scores.json\"\n",
    "\n",
    "# load lmunit dialogue files\n",
    "with open(autotod_lmunit_path, 'r') as f:\n",
    "\tautotod_lmunit_judge = json.load(f)\n",
    "autotod_lmunit_dials = autotod_lmunit_judge['dialogues']\n",
    "with open(tau_lmunit_path) as f:\n",
    "\ttau_lmunit_judge = json.load(f)\n",
    "tau_lmunit_dials = tau_lmunit_judge['dialogues']\n",
    "with open(lmunit_dial_level_path, 'r') as f:\n",
    "\tlmunit_dial_level = json.load(f)\n",
    "\n",
    "lmunit_batch_scores = {}\n",
    "for i in batch_dials.keys():\n",
    "\tif i not in human_eval_csv:\n",
    "\t\tcontinue\n",
    "\tturn_scores, dial_scores = extract_lmunit_scores(\n",
    "\t\tautotod_lmunit_dials,\n",
    "\t\ttau_lmunit_dials,\n",
    "\t\tlmunit_dial_level,\n",
    "\t\tbatch_order[i]\n",
    "\t)\n",
    "\tlmunit_batch_scores[i] = {\n",
    "\t\t\"turn_level\": turn_scores, \n",
    "\t\t\"dial_level\": dial_scores \n",
    "\t}\n",
    "pprint.pprint(lmunit_batch_scores, compact=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3632fb41",
   "metadata": {},
   "source": [
    "#### Extract Inform/Success of AutoTOD and Tau Reward from Tau Bench"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2ba4695",
   "metadata": {},
   "outputs": [],
   "source": [
    "autotod_dial_path = \"datasets/out_basic_100_fm_eval.json\"\n",
    "tau_airline_dial_path = \"results/agent-results-tau/tool-calling-gpt-4o-0.0_range_0--1_user-gpt-4o-llm_0114160308-airline.json\"\n",
    "tau_retail_dial_path = \"results/agent-results-tau/tool-calling-gpt-4o-0.0_range_0--1_user-gpt-4o-llm_0114161231-retail.json\"\n",
    "\n",
    "with open(autotod_dial_path, 'r') as f:\n",
    "\tautotod_dial = json.load(f)\n",
    "with open(tau_airline_dial_path, 'r') as f:\n",
    "\ttau_airline_dial = json.load(f)\n",
    "with open(tau_retail_dial_path, 'r') as f:\n",
    "\ttau_retail_dial = json.load(f)\n",
    "\n",
    "def extract_trad_scores(\n",
    "\tautotod_dial: dict,\n",
    "\ttau_airline_dial: list,\n",
    "\ttau_retail_dial: list,\n",
    "\tbatch_order: dict\n",
    ") -> dict:\n",
    "\t# extract autotod and tau bench dialogue scores\n",
    "\tdial_scores = {}\n",
    "\tfor batch_dial in batch_order:\n",
    "\t\t# convert batch dial id format\n",
    "\t\tbatch_dial_id = batch_dial[\"id\"]\n",
    "\t\tif batch_dial[\"type\"] == \"autotod_mwoz\":\n",
    "\t\t\tprev_autotod_id = f\"{batch_dial_id.upper()}.json\"\n",
    "\t\t\tdial_summary = autotod_dial[prev_autotod_id][\"eval_summary\"]\n",
    "\t\t\t# inform and success are only 1 if all domains are successful, otherwise 0\n",
    "\t\t\tinform = True\n",
    "\t\t\tsuccess = True\n",
    "\t\t\tfor domain, values in dial_summary.items():\n",
    "\t\t\t\tif \"inform\" in values:\n",
    "\t\t\t\t\tinform = inform and values[\"inform\"]\n",
    "\t\t\t\tif \"success\" in values:\n",
    "\t\t\t\t\tsuccess = success and values[\"success\"]\n",
    "\t\t\tscore = { \"inform\": int(inform), \"success\": int(success) }\n",
    "\t\telif batch_dial['type'] == \"tau_retail\":\n",
    "\t\t\tscore = tau_retail_dial[int(batch_dial_id)][\"reward\"]\n",
    "\t\t\tbatch_dial_id = f\"retail_{batch_dial_id}\"\n",
    "\t\telif batch_dial['type'] == \"tau_airline\":\n",
    "\t\t\tscore = tau_airline_dial[int(batch_dial_id)][\"reward\"]\n",
    "\t\t\tbatch_dial_id = f\"airline_{batch_dial_id}\"\n",
    "\t\tdial_scores[batch_dial_id] = score\n",
    "\treturn dial_scores\n",
    "\n",
    "trad_batch_scores = {}\n",
    "for i in batch_dials.keys():\n",
    "\tif i not in human_eval_csv:\n",
    "\t\tcontinue\n",
    "\ttrad_scores = extract_trad_scores(\n",
    "\t\tautotod_dial,\n",
    "\t\ttau_airline_dial,\n",
    "\t\ttau_retail_dial,\n",
    "\t\tbatch_order[i]\n",
    "\t)\n",
    "\ttrad_batch_scores[i] = trad_scores\n",
    "pprint.pprint(trad_batch_scores, compact=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dd8a947",
   "metadata": {},
   "source": [
    "#### Extract Traditional Automatic Inform/Success (MultiWOZ) and Reward (Tau) Scores of MultiWOZ with Tau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31a3f88b",
   "metadata": {},
   "outputs": [],
   "source": [
    "mwoz_dial_path = \"datasets/basic_result_final.json\"\n",
    "\n",
    "with open(mwoz_dial_path, 'r') as f:\n",
    "\tmwoz_dial = json.load(f)\n",
    "\n",
    "def extract_all_trad_auto_scores(\n",
    "\tmwoz_dial: dict,\n",
    "\ttau_airline_dial: list,\n",
    "\ttau_retail_dial: list,\n",
    "\tbatch_order: dict\n",
    ") -> dict:\n",
    "\t# extract mwoz and tau bench dialogue scores\n",
    "\ttrad_auto_scores = {}\n",
    "\tfor batch_dial in batch_order:\n",
    "\t\t# convert batch dial id format\n",
    "\t\tbatch_dial_id = batch_dial[\"id\"]\n",
    "\t\tif batch_dial[\"type\"] == \"autotod_mwoz\":\n",
    "\t\t\tprev_mwoz_id = f\"{batch_dial_id.upper()}.json\"\n",
    "\t\t\t# inform and success are only 1 if all domains are successful, otherwise 0\n",
    "\t\t\tinform = True\n",
    "\t\t\tsuccess = True\n",
    "\t\t\tinform_scores = mwoz_dial[prev_mwoz_id][\"match\"]\n",
    "\t\t\tif \"total\" in inform_scores:\n",
    "\t\t\t\tinform = inform_scores[\"total\"]\n",
    "\t\t\tsuccess_scores = mwoz_dial[prev_mwoz_id][\"success\"]\n",
    "\t\t\tif \"total\" in success_scores:\n",
    "\t\t\t\tsuccess = success_scores[\"total\"]\n",
    "\t\t\tscore = inform and success\n",
    "\t\telif batch_dial['type'] == \"tau_retail\":\n",
    "\t\t\tscore = tau_retail_dial[int(batch_dial_id)][\"reward\"]\n",
    "\t\t\tbatch_dial_id = f\"retail_{batch_dial_id}\"\n",
    "\t\telif batch_dial['type'] == \"tau_airline\":\n",
    "\t\t\tscore = tau_airline_dial[int(batch_dial_id)][\"reward\"]\n",
    "\t\t\tbatch_dial_id = f\"airline_{batch_dial_id}\"\n",
    "\t\ttrad_auto_scores[batch_dial_id] = int(score)\n",
    "\treturn trad_auto_scores\n",
    "\n",
    "trad_auto_batch_scores = {}\n",
    "trad_auto_mwoz_batch_scores = {}\n",
    "tau_batch_scores = {}\n",
    "for i in batch_dials.keys():\n",
    "\tif i not in human_eval_csv:\n",
    "\t\tcontinue\n",
    "\ttrad_auto_scores = extract_all_trad_auto_scores(\n",
    "\t\tmwoz_dial,\n",
    "\t\ttau_airline_dial,\n",
    "\t\ttau_retail_dial,\n",
    "\t\tbatch_order[i]\n",
    "\t)\n",
    "\ttrad_auto_batch_scores[i] = trad_auto_scores\n",
    "\ttrad_auto_mwoz_batch_scores[i] = trad_auto_mwoz_scores\n",
    "\ttau_batch_scores[i] = trad_scores\n",
    "pprint.pprint(trad_auto_batch_scores, compact=True)\n",
    "pprint.pprint(trad_auto_mwoz_batch_scores, compact=True)\n",
    "pprint.pprint(tau_batch_scores, compact=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dc54fd0",
   "metadata": {},
   "source": [
    "#### Inter-Rater Agreement Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "532e180b",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def calculate_krippendorff_alpha(data: np.ndarray) -> float:\n",
    "\t\"\"\"Calculate Krippendorff's alpha for ordinal data\"\"\"\n",
    "\ttry:\n",
    "\t\treturn alpha(\n",
    "\t\t\treliability_data=data.astype(np.int64), \n",
    "\t\t\tvalue_domain=[1,2,3,4,5], \n",
    "\t\t\tlevel_of_measurement='interval'\n",
    "\t\t)\n",
    "\texcept Exception as e:\n",
    "\t\t\tprint(f\"Krippendorff calculation error: {e}\")\n",
    "\t\t\treturn None\n",
    "\n",
    "def calculate_kappa(data: np.ndarray, n_cat: int) -> dict:\n",
    "\t\"\"\"Calculate kappa statistic for more than 2 raters (fleiss and randolph)\"\"\"\n",
    "\ttry:\n",
    "\t\tdata_table, _ = aggregate_raters(data=data, n_cat=n_cat)\n",
    "\t\t# randolph method gives best performance\n",
    "\t\tfleiss = fleiss_kappa(table=data_table, method='fleiss') \n",
    "\t\trandolph = fleiss_kappa(table=data_table, method='randolph') \n",
    "\t\treturn {\"fleiss\": float(fleiss), \"randolph\": float(randolph)}\n",
    "\texcept Exception as e:\n",
    "\t\tprint(f\"Fleiss calculation error: {e}\")\n",
    "\t\treturn None\n",
    "\n",
    "def calculate_cohen_kappa(data: np.ndarray, n_cat: int) -> float:\n",
    "\t\"\"\"Calculate Cohen's kappa for 2 raters\"\"\"\n",
    "\ttry:\n",
    "\t\tdata_table, _ = to_table(data=data, bins=n_cat)\n",
    "\t\treturn cohens_kappa(table=data_table, wt='linear')['kappa']\n",
    "\texcept Exception as e:\n",
    "\t\tprint(f\"Cohen calculation error: {e}\")\n",
    "\t\treturn None\n",
    "\t\n",
    "def calculate_gwet_ac(data: np.ndarray) -> float:\n",
    "\t\"\"\"Calculate Gwet's AC1 for data with skew in distribution\"\"\"\n",
    "\tcac_raters = CAC(pd.DataFrame(data))\n",
    "\tgwet = cac_raters.gwet()\n",
    "\t# pprint.pprint(gwet, compact=True)\n",
    "\treturn float(gwet['est']['coefficient_value'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83a3f399",
   "metadata": {},
   "source": [
    "#### Calculate Turn-Level Correlations: Human vs TD-Eval, LMUnit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1303b275",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compile_all_scores_turn_level(\n",
    "\thuman_batch_scores: dict, \n",
    "\ttdeval_batch_scores: dict, \n",
    "\tlmunit_batch_scores: dict\n",
    "):\n",
    "\tdims = ['conv_consistency', 'backend_consistency', 'policy_completeness']\n",
    "\t# organize scores by batch\n",
    "\tbatch_human_scores = {}\n",
    "\tbatch_tdeval_scores = {}\n",
    "\tbatch_lmunit_scores = {}\n",
    "\tbatch_inform_reward_scores = {}\n",
    "\t# consolidate scores into one large array\n",
    "\tall_human_scores = []\n",
    "\tall_tdeval_scores = []\n",
    "\tall_lmunit_scores = []\n",
    "\tfor bId in human_batch_scores.keys():\n",
    "\t\thuman_dials = human_batch_scores[bId][\"turn_level\"]\n",
    "\t\ttdeval_dials = tdeval_batch_scores[bId][\"turn_level\"]\n",
    "\t\tlmunit_dials = lmunit_batch_scores[bId][\"turn_level\"]\n",
    "\t\tbatch_human_scores[bId] = []\n",
    "\t\tbatch_tdeval_scores[bId] = []\n",
    "\t\tbatch_lmunit_scores[bId] = []\n",
    "\t\tbatch_inform_reward_scores[bId] = []\n",
    "\t\tfor dId in human_dials.keys():\n",
    "\t\t\thuman_scores = human_dials[dId]\n",
    "\t\t\ttdeval_scores = tdeval_dials[dId]\n",
    "\t\t\tlmunit_scores = lmunit_dials[dId]\n",
    "\t\t\tfor metric in dims:\n",
    "\t\t\t\tbatch_human_scores[bId] = np.concat(\n",
    "\t\t\t\t\t(batch_human_scores[bId], human_scores[metric])\n",
    "\t\t\t\t)\n",
    "\t\t\t\tall_human_scores = np.concat(\n",
    "\t\t\t\t\t(all_human_scores, human_scores[metric])\n",
    "\t\t\t\t)\n",
    "\t\t\t\tbatch_tdeval_scores[bId] = np.concat(\n",
    "\t\t\t\t\t(batch_tdeval_scores[bId], tdeval_scores[metric])\n",
    "\t\t\t\t)\n",
    "\t\t\t\tall_tdeval_scores = np.concat(\n",
    "\t\t\t\t\t(all_tdeval_scores, tdeval_scores[metric])\n",
    "\t\t\t\t)\n",
    "\t\t\t\tbatch_lmunit_scores[bId] = np.concat(\n",
    "\t\t\t\t\t(batch_lmunit_scores[bId], lmunit_scores[metric])\n",
    "\t\t\t\t)\n",
    "\t\t\t\tall_lmunit_scores = np.concat(\n",
    "\t\t\t\t\t(all_lmunit_scores, lmunit_scores[metric])\n",
    "\t\t\t\t)\n",
    "\treturn {\n",
    "\t\t'batch': {\n",
    "\t\t\t'human': batch_human_scores,\n",
    "\t\t\t'tdeval': batch_tdeval_scores,\n",
    "\t\t\t'lmunit': batch_lmunit_scores\n",
    "\t\t},\n",
    "\t\t\"all\": {\n",
    "\t\t\t'human': all_human_scores,\n",
    "\t\t\t'tdeval': all_tdeval_scores,\n",
    "\t\t\t'lmunit': all_lmunit_scores\n",
    "\t\t}\n",
    "\t}\n",
    "\n",
    "def map_all_correlations_dial_level(\n",
    "\thuman_scores: dict, \n",
    "\ttdeval_scores: dict, \n",
    "\tlmunit_scores: dict, \n",
    "):\n",
    "\t# take correlation by metric (conv)\n",
    "\thuman_conv = human_scores[::3]\n",
    "\ttdeval_conv = tdeval_scores[::3]\n",
    "\tlmunit_conv = lmunit_scores[::3]\n",
    "\ttdeval_conv_co, tdeval_conv_p = stats.spearmanr(\n",
    "\t\thuman_conv, \n",
    "\t\ttdeval_conv\n",
    "\t)\n",
    "\tlmunit_conv_co, lmunit_conv_p = stats.spearmanr(\n",
    "\t\thuman_conv, \n",
    "\t\tlmunit_conv\n",
    "\t)\n",
    "\t# take correlation by metric (backend)\n",
    "\thuman_backend = human_scores[1::3]\n",
    "\ttdeval_backend = tdeval_scores[1::3]\n",
    "\tlmunit_backend = lmunit_scores[1::3]\n",
    "\ttdeval_backend_co, tdeval_backend_p = stats.spearmanr(\n",
    "\t\thuman_backend, \n",
    "\t\ttdeval_backend\n",
    "\t)\n",
    "\tlmunit_backend_co, lmunit_backend_p = stats.spearmanr(\n",
    "\t\thuman_backend, \n",
    "\t\tlmunit_backend\n",
    "\t)\n",
    "\t# take correlation by metric (policy)\n",
    "\thuman_policy = human_scores[2::3]\n",
    "\ttdeval_policy = tdeval_scores[2::3]\n",
    "\tlmunit_policy = lmunit_scores[2::3]\n",
    "\ttdeval_policy_co, tdeval_policy_p = stats.spearmanr(\n",
    "\t\thuman_policy, \n",
    "\t\ttdeval_policy\n",
    "\t)\n",
    "\tlmunit_policy_co, lmunit_policy_p = stats.spearmanr(\n",
    "\t\thuman_policy, \n",
    "\t\tlmunit_policy\n",
    "\t)\n",
    "\t# take correlation by averaging metrics\n",
    "\thuman_overall = human_scores\n",
    "\ttdeval_overall = tdeval_scores\n",
    "\tlmunit_overall = lmunit_scores\n",
    "\ttdeval_overall_co, tdeval_overall_p = stats.spearmanr(\n",
    "\t\thuman_overall, \n",
    "\t\ttdeval_overall\n",
    "\t)\n",
    "\toverall_lmunit_co, overall_lmunit_p = stats.spearmanr(\n",
    "\t\thuman_overall, \n",
    "\t\tlmunit_overall\n",
    "\t)\n",
    "\tdial_corrs = {\n",
    "\t\t\"human-tdeval\": {\n",
    "\t\t\t\"conv\": {\n",
    "\t\t\t\t\"coeff\": round(float(tdeval_conv_co), 3), \n",
    "\t\t\t\t\"pval\": round(float(tdeval_conv_p), 3)\n",
    "\t\t\t}, \n",
    "\t\t\t\"backend\": {\n",
    "\t\t\t\t\"coeff\": round(float(tdeval_backend_co), 3), \n",
    "\t\t\t\t\"pval\": round(float(tdeval_backend_p), 3) \n",
    "\t\t\t},\n",
    "\t\t\t\"policy\": {\n",
    "\t\t\t\t\"coeff\": round(float(tdeval_policy_co), 3), \n",
    "\t\t\t\t\"pval\": round(float(tdeval_policy_p), 3) \n",
    "\t\t\t},\n",
    "\t\t\t\"overall\": {\n",
    "\t\t\t\t\"coeff\": round(float(tdeval_overall_co), 3), \n",
    "\t\t\t\t\"pval\": round(float(tdeval_overall_p), 3)\n",
    "\t\t\t},\n",
    "\t\t},\n",
    "\t\t\"human-lmunit\": {\n",
    "\t\t\t\"conv\": {\n",
    "\t\t\t\t\"coeff\": round(float(lmunit_conv_co), 3), \n",
    "\t\t\t\t\"pval\": round(float(lmunit_conv_p), 3) \n",
    "\t\t\t}, \n",
    "\t\t\t\"backend\": {\n",
    "\t\t\t\t\"coeff\": round(float(lmunit_backend_co), 3), \n",
    "\t\t\t\t\"pval\": round(float(lmunit_backend_p), 3) \n",
    "\t\t\t},\n",
    "\t\t\t\"policy\": {\n",
    "\t\t\t\t\"coeff\": round(float(lmunit_policy_co), 3), \n",
    "\t\t\t\t\"pval\": round(float(lmunit_policy_p), 3) \n",
    "\t\t\t},\n",
    "\t\t\t\"overall\": {\n",
    "\t\t\t\t\"coeff\": round(float(overall_lmunit_co), 3), \n",
    "\t\t\t\t\"pval\": round(float(overall_lmunit_p), 3) \n",
    "\t\t\t},\n",
    "\t\t},\n",
    "\t}\n",
    "\treturn dial_corrs\n",
    "\n",
    "def calculate_turn_level_corrs(\n",
    "\thuman_batch_scores: dict, \n",
    "\ttdeval_batch_scores: dict, \n",
    "\tlmunit_batch_scores: dict\n",
    "):\n",
    "\tcompiled_scores = compile_all_scores_turn_level(\t\n",
    "\t\thuman_batch_scores, \n",
    "\t\ttdeval_batch_scores, \n",
    "\t\tlmunit_batch_scores,\n",
    "\t)\n",
    "\t# serialize batched compile scores\n",
    "\tbatch_human_scores = compiled_scores['batch']['human']\n",
    "\tbatch_tdeval_scores = compiled_scores['batch']['tdeval']\n",
    "\tbatch_lmunit_scores = compiled_scores['batch']['lmunit']\n",
    "\t# serialized fully compiled scores\n",
    "\tall_human_scores = compiled_scores['all']['human']\n",
    "\tall_tdeval_scores = compiled_scores['all']['tdeval']\n",
    "\tall_lmunit_scores = compiled_scores['all']['lmunit']\n",
    "\t# take correlation for each batch\n",
    "\tturn_corrs = {}\n",
    "\tfor bId in human_batch_scores.keys():\n",
    "\t\tturn_corrs[bId] = map_all_correlations_dial_level(\n",
    "\t\t\tbatch_human_scores[bId], \n",
    "\t\t\tbatch_tdeval_scores[bId], \n",
    "\t\t\tbatch_lmunit_scores[bId], \n",
    "\t\t)\n",
    "\tturn_corrs[\"all\"] = map_all_correlations_dial_level(\n",
    "\t\tall_human_scores,\n",
    "\t\tall_tdeval_scores,\n",
    "\t\tall_lmunit_scores,\n",
    "\t)\n",
    "\treturn turn_corrs\n",
    "\n",
    "turn_level_corr = calculate_turn_level_corrs(\n",
    "\thuman_batch_scores, \n",
    "\ttdeval_batch_scores, \n",
    "\tlmunit_batch_scores\n",
    ")\n",
    "pprint.pprint(turn_level_corr[\"all\"], compact=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "443b39dd",
   "metadata": {},
   "source": [
    "#### Calculate IRR For Turn Level Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7abe8275",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_all_irr_turn_level(\n",
    "\thuman_scores: dict, \n",
    "\ttdeval_scores: dict, \n",
    "\tlmunit_scores: dict\n",
    "):\n",
    "\t# take IRR by metric (conv)\n",
    "\thuman_conv = human_scores[::3]\n",
    "\ttdeval_conv = tdeval_scores[::3]\n",
    "\tlmunit_conv = lmunit_scores[::3]\n",
    "\n",
    "\thuman_tdeval_conv = np.vstack(\n",
    "\t\t(human_conv, tdeval_conv)\n",
    "\t).astype(dtype=np.int64)\n",
    "\thuman_tdeval_conv_gwet = calculate_gwet_ac(human_tdeval_conv)\n",
    "\thuman_tdeval_conv_kappa = calculate_kappa(\n",
    "\t\thuman_tdeval_conv-1, \n",
    "\t\tn_cat=5\n",
    "\t)['randolph']\n",
    "\n",
    "\thuman_lmunit_conv = np.vstack(\n",
    "\t\t(human_conv, lmunit_conv)\n",
    "\t).astype(dtype=np.int64)\n",
    "\thuman_lmunit_conv_gwet = calculate_gwet_ac(human_lmunit_conv)\n",
    "\thuman_lmunit_conv_kappa = calculate_kappa(\n",
    "\t\thuman_lmunit_conv-1, \n",
    "\t\tn_cat=5\n",
    "\t)['randolph']\n",
    "\n",
    "\t# take correlation by metric (backend)\n",
    "\thuman_backend = human_scores[1::3]\n",
    "\ttdeval_backend = tdeval_scores[1::3]\n",
    "\tlmunit_backend = lmunit_scores[1::3]\n",
    "\t\n",
    "\thuman_tdeval_backend = np.vstack(\n",
    "\t\t(human_backend, tdeval_backend)\n",
    "\t).astype(dtype=np.int64)\n",
    "\thuman_tdeval_backend_gwet = calculate_gwet_ac(human_tdeval_backend)\n",
    "\thuman_tdeval_backend_kappa = calculate_kappa(\n",
    "\t\thuman_tdeval_backend-1, \n",
    "\t\tn_cat=5\n",
    "\t)['randolph']\n",
    "\n",
    "\thuman_lmunit_backend = np.vstack(\n",
    "\t\t(human_backend, lmunit_backend)\n",
    "\t).astype(dtype=np.int64)\n",
    "\thuman_lmunit_backend_gwet = calculate_gwet_ac(human_lmunit_backend)\n",
    "\thuman_lmunit_backend_kappa = calculate_kappa(\n",
    "\t\thuman_lmunit_backend-1, \n",
    "\t\tn_cat=5\n",
    "\t)['randolph']\n",
    "\n",
    "\t# take correlation by metric (policy)\n",
    "\thuman_policy = human_scores[2::3]\n",
    "\ttdeval_policy = tdeval_scores[2::3]\n",
    "\tlmunit_policy = lmunit_scores[2::3]\n",
    "\n",
    "\thuman_tdeval_policy = np.vstack(\n",
    "\t\t(human_policy, tdeval_policy)\n",
    "\t).astype(dtype=np.int64)\n",
    "\thuman_tdeval_policy_gwet = calculate_gwet_ac(human_tdeval_policy)\n",
    "\thuman_tdeval_policy_kappa = calculate_kappa(\n",
    "\t\thuman_tdeval_policy-1, \n",
    "\t\tn_cat=5\n",
    "\t)['randolph']\n",
    "\n",
    "\thuman_lmunit_policy = np.vstack(\n",
    "\t\t(human_policy, lmunit_policy)\n",
    "\t).astype(dtype=np.int64)\n",
    "\thuman_lmunit_policy_gwet = calculate_gwet_ac(human_lmunit_policy)\n",
    "\thuman_lmunit_policy_kappa = calculate_kappa(\n",
    "\t\thuman_lmunit_policy-1, \n",
    "\t\tn_cat=5\n",
    "\t)['randolph']\n",
    "\n",
    "\t# take IRR of all metrics (overall)\n",
    "\toverall_human = human_scores\n",
    "\toverall_tdeval = tdeval_scores\n",
    "\toverall_lmunit = lmunit_scores\n",
    "\n",
    "\toverall_human_tdeval = np.vstack(\n",
    "\t\t(overall_human, overall_tdeval)\n",
    "\t).astype(dtype=np.int64)\n",
    "\toverall_human_tdeval_gwet = calculate_gwet_ac(overall_human_tdeval)\n",
    "\toverall_human_tdeval_kappa = calculate_kappa(\n",
    "\t\toverall_human_tdeval-1, \n",
    "\t\t5\n",
    "\t)['randolph']\n",
    "\n",
    "\toverall_human_lmunit = np.vstack(\n",
    "\t\t(overall_human, overall_lmunit)\n",
    "\t).astype(dtype=np.int64)\n",
    "\toverall_human_lmunit_gwet = calculate_gwet_ac(overall_human_lmunit)\n",
    "\toverall_human_lmunit_kappa = calculate_kappa(\n",
    "\t\toverall_human_lmunit-1,\n",
    "\t\t5\n",
    "\t)['randolph']\n",
    "\n",
    "\tdial_irr = {\n",
    "\t\t\"human-tdeval\": {\n",
    "\t\t\t\"conv\": {\n",
    "\t\t\t\t\"gwet-ac1\": human_tdeval_conv_gwet,\n",
    "\t\t\t\t\"r_kappa\": human_tdeval_conv_kappa\n",
    "\t\t\t}, \n",
    "\t\t\t\"backend\": {\n",
    "\t\t\t\t\"gwet-ac1\": human_tdeval_backend_gwet,\n",
    "\t\t\t\t\"r_kappa\": human_tdeval_backend_kappa\n",
    "\t\t\t},\n",
    "\t\t\t\"policy\": {\n",
    "\t\t\t\t\"gwet-ac1\": human_tdeval_policy_gwet,\n",
    "\t\t\t\t\"r_kappa\": human_tdeval_policy_kappa\n",
    "\t\t\t},\n",
    "\t\t\t\"overall\": {\n",
    "\t\t\t\t\"gwet-ac1\": overall_human_tdeval_gwet,\n",
    "\t\t\t\t\"r_kappa\": overall_human_tdeval_kappa\n",
    "\t\t\t},\n",
    "\t\t},\n",
    "\t\t\"human-lmunit\": {\n",
    "\t\t\t\"conv\": {\n",
    "\t\t\t\t\"gwet-ac1\": human_lmunit_conv_gwet,\n",
    "\t\t\t\t\"r_kappa\": human_lmunit_conv_kappa\n",
    "\t\t\t},\n",
    "\t\t\t\"backend\": {\n",
    "\t\t\t\t\"gwet-ac1\": human_lmunit_backend_gwet,\n",
    "\t\t\t\t\"r_kappa\": human_lmunit_backend_kappa\n",
    "\t\t\t},\n",
    "\t\t\t\"policy\": {\n",
    "\t\t\t\t\"gwet-ac1\": human_lmunit_policy_gwet,\n",
    "\t\t\t\t\"r_kappa\": human_lmunit_policy_kappa\n",
    "\t\t\t},\n",
    "\t\t\t\"overall\": {\n",
    "\t\t\t\t\"gwet-ac1\": overall_human_lmunit_gwet,\n",
    "\t\t\t\t\"r_kappa\": overall_human_lmunit_kappa\n",
    "\t\t\t},\n",
    "\t\t},\n",
    "\t}\n",
    "\treturn dial_irr\n",
    "\n",
    "\n",
    "def calculate_turn_level_irr(\n",
    "\thuman_batch_scores: dict, \n",
    "\ttdeval_batch_scores: dict, \n",
    "\tlmunit_batch_scores: dict\n",
    "):\n",
    "\tcompiled_scores = compile_all_scores_turn_level(\t\n",
    "\t\thuman_batch_scores, \n",
    "\t\ttdeval_batch_scores, \n",
    "\t\tlmunit_batch_scores,\n",
    "\t)\n",
    "\t# serialize batched compile scores\n",
    "\tbatch_human_scores = compiled_scores['batch']['human']\n",
    "\tbatch_tdeval_scores = compiled_scores['batch']['tdeval']\n",
    "\tbatch_lmunit_scores = compiled_scores['batch']['lmunit']\n",
    "\t# serialized fully compiled scores\n",
    "\tall_human_scores = compiled_scores['all']['human']\n",
    "\tall_tdeval_scores = compiled_scores['all']['tdeval']\n",
    "\tall_lmunit_scores = compiled_scores['all']['lmunit']\n",
    "\t# take correlation for each batch\n",
    "\tturn_irr = {}\n",
    "\tfor bId in human_batch_scores.keys():\n",
    "\t\tturn_irr[bId] = map_all_irr_turn_level(\n",
    "\t\t\tbatch_human_scores[bId], \n",
    "\t\t\tbatch_tdeval_scores[bId], \n",
    "\t\t\tbatch_lmunit_scores[bId]\n",
    "\t\t)\n",
    "\tturn_irr[\"all\"] = map_all_irr_turn_level(\n",
    "\t\tall_human_scores,\n",
    "\t\tall_tdeval_scores,\n",
    "\t\tall_lmunit_scores\n",
    "\t)\n",
    "\treturn turn_irr\n",
    "\n",
    "turn_level_irr = calculate_turn_level_irr(\n",
    "\thuman_batch_scores, \n",
    "\ttdeval_batch_scores, \n",
    "\tlmunit_batch_scores\n",
    ")\n",
    "pprint.pprint(turn_level_irr[\"all\"], compact=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f681580",
   "metadata": {},
   "source": [
    "#### Calculate Dialogue-Level Agreement (Spearman): Human vs TD-Eval, LMUnit, AutoTOD, Inform/Success + Tau Reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0afc0055",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def map_all_correlations_dial_level(\n",
    "\thuman_scores: np.ndarray, \n",
    "\ttdeval_scores: np.ndarray, \n",
    "\tlmunit_scores: np.ndarray, \n",
    "\tinform_reward_scores: np.ndarray, \n",
    "\tsuccess_reward_scores: np.ndarray, \n",
    "\ttrad_auto_scores: np.ndarray\n",
    "):\n",
    "\t# take correlation by metric (conv)\n",
    "\thuman_conv = human_scores[::3]\n",
    "\ttdeval_conv = tdeval_scores[::3]\n",
    "\ttdeval_conv_co, tdeval_conv_p = stats.spearmanr(\n",
    "\t\thuman_conv, \n",
    "\t\ttdeval_conv\n",
    "\t)\n",
    "\tlmunit_conv_co, lmunit_conv_p = stats.spearmanr(\n",
    "\t\thuman_conv, \n",
    "\t\tlmunit_scores\n",
    "\t)\n",
    "\tinform_reward_conv_co, inform_reward_conv_p = stats.spearmanr(\n",
    "\t\thuman_conv, \n",
    "\t\tinform_reward_scores\n",
    "\t)\n",
    "\tsuccess_reward_conv_co, success_reward_conv_p = stats.spearmanr(\n",
    "\t\thuman_conv, \n",
    "\t\tsuccess_reward_scores\n",
    "\t)\n",
    "\ttrad_auto_conv_co, trad_auto_conv_p = stats.spearmanr(\n",
    "\t\thuman_conv, \n",
    "\t\ttrad_auto_scores\n",
    "\t)\n",
    "\t# take correlation by metric (backend)\n",
    "\thuman_backend = human_scores[1::3]\n",
    "\ttdeval_backend = tdeval_scores[1::3]\n",
    "\ttdeval_backend_co, tdeval_backend_p = stats.spearmanr(\n",
    "\t\thuman_backend, \n",
    "\t\ttdeval_backend\n",
    "\t)\n",
    "\tlmunit_backend_co, lmunit_backend_p = stats.spearmanr(\n",
    "\t\thuman_backend, \n",
    "\t\tlmunit_scores\n",
    "\t)\n",
    "\tinform_reward_backend_co, inform_reward_backend_p = stats.spearmanr(\n",
    "\t\thuman_backend, \n",
    "\t\tinform_reward_scores\n",
    "\t)\n",
    "\tsuccess_reward_backend_co, success_reward_backend_p = stats.spearmanr(\n",
    "\t\thuman_backend, \n",
    "\t\tsuccess_reward_scores\n",
    "\t)\n",
    "\ttrad_auto_backend_co, trad_auto_backend_p = stats.spearmanr(\n",
    "\t\thuman_backend, \n",
    "\t\ttrad_auto_scores\n",
    "\t)\n",
    "\t# take correlation by metric (policy)\n",
    "\thuman_policy = human_scores[2::3]\n",
    "\ttdeval_policy = tdeval_scores[2::3]\n",
    "\ttdeval_policy_co, tdeval_policy_p = stats.spearmanr(\n",
    "\t\thuman_policy, \n",
    "\t\ttdeval_policy\n",
    "\t)\n",
    "\tlmunit_policy_co, lmunit_policy_p = stats.spearmanr(\n",
    "\t\thuman_policy, \n",
    "\t\tlmunit_scores\n",
    "\t)\n",
    "\tinform_reward_policy_co, inform_reward_policy_p = stats.spearmanr(\n",
    "\t\thuman_policy, \n",
    "\t\tinform_reward_scores\n",
    "\t)\n",
    "\tsuccess_reward_policy_co, success_reward_policy_p = stats.spearmanr(\n",
    "\t\thuman_policy, \n",
    "\t\tsuccess_reward_scores\n",
    "\t)\n",
    "\ttrad_auto_policy_co, trad_auto_policy_p = stats.spearmanr(\n",
    "\t\thuman_policy, \n",
    "\t\ttrad_auto_scores\n",
    "\t)\n",
    "\t# take correlation by averaging metrics\n",
    "\tavg_human_scores = np.mean(\n",
    "\t\thuman_scores.reshape((-1, 3)), \n",
    "\t\taxis=1\n",
    "\t)\n",
    "\thuman_overall = human_scores\n",
    "\ttdeval_overall = tdeval_scores\n",
    "\ttdeval_overall_co, tdeval_overall_p = stats.spearmanr(\n",
    "\t\thuman_overall, \n",
    "\t\ttdeval_overall\n",
    "\t)\n",
    "\toverall_lmunit_co, overall_lmunit_p = stats.spearmanr(\n",
    "\t\tavg_human_scores, \n",
    "\t\tlmunit_scores\n",
    "\t)\n",
    "\toverall_inform_reward_co, overall_inform_reward_p = stats.spearmanr(\n",
    "\t\tavg_human_scores, \n",
    "\t\tinform_reward_scores\n",
    "\t)\n",
    "\toverall_success_reward_co, overall_success_reward_p = stats.spearmanr(\n",
    "\t\tavg_human_scores, \n",
    "\t\tsuccess_reward_scores\n",
    "\t)\n",
    "\toverall_trad_auto_co, overall_trad_auto_p = stats.spearmanr(\n",
    "\t\tavg_human_scores,\n",
    "\t\ttrad_auto_scores\n",
    "\t)\n",
    "\tdial_corrs = {\n",
    "\t\t\"human-tdeval\": {\n",
    "\t\t\t\"conv\": {\n",
    "\t\t\t\t\"coeff\": round(float(tdeval_conv_co), 3), \n",
    "\t\t\t\t\"pval\": round(float(tdeval_conv_p), 3)\n",
    "\t\t\t}, \n",
    "\t\t\t\"backend\": {\n",
    "\t\t\t\t\"coeff\": round(float(tdeval_backend_co), 3), \n",
    "\t\t\t\t\"pval\": round(float(tdeval_backend_p), 3) \n",
    "\t\t\t},\n",
    "\t\t\t\"policy\": {\n",
    "\t\t\t\t\"coeff\": round(float(tdeval_policy_co), 3), \n",
    "\t\t\t\t\"pval\": round(float(tdeval_policy_p), 3) \n",
    "\t\t\t},\n",
    "\t\t\t\"overall\": {\n",
    "\t\t\t\t\"coeff\": round(float(tdeval_overall_co), 3), \n",
    "\t\t\t\t\"pval\": round(float(tdeval_overall_p), 3)\n",
    "\t\t\t},\n",
    "\t\t},\n",
    "\t\t\"human-lmunit\": {\n",
    "\t\t\t\"conv\": {\n",
    "\t\t\t\t\"coeff\": round(float(lmunit_conv_co), 3), \n",
    "\t\t\t\t\"pval\": round(float(lmunit_conv_p), 3) \n",
    "\t\t\t}, \n",
    "\t\t\t\"backend\": {\n",
    "\t\t\t\t\"coeff\": round(float(lmunit_backend_co), 3), \n",
    "\t\t\t\t\"pval\": round(float(lmunit_backend_p), 3) \n",
    "\t\t\t},\n",
    "\t\t\t\"policy\": {\n",
    "\t\t\t\t\"coeff\": round(float(lmunit_policy_co), 3), \n",
    "\t\t\t\t\"pval\": round(float(lmunit_policy_p), 3) \n",
    "\t\t\t},\n",
    "\t\t\t\"overall\": {\n",
    "\t\t\t\t\"coeff\": round(float(overall_lmunit_co), 3), \n",
    "\t\t\t\t\"pval\": round(float(overall_lmunit_p), 3) \n",
    "\t\t\t},\n",
    "\t\t},\n",
    "\t\t\"human-inform_reward\": {\n",
    "\t\t\t\"conv\": {\n",
    "\t\t\t\t\"coeff\": round(float(inform_reward_conv_co), 3), \n",
    "\t\t\t\t\"pval\": round(float(inform_reward_conv_p), 3)\n",
    "\t\t\t}, \n",
    "\t\t\t\"backend\": {\n",
    "\t\t\t\t\"coeff\": round(float(inform_reward_backend_co), 3), \n",
    "\t\t\t\t\"pval\": round(float(inform_reward_backend_p), 3) \n",
    "\t\t\t},\n",
    "\t\t\t\"policy\": {\n",
    "\t\t\t\t\"coeff\": round(float(inform_reward_policy_co), 3), \n",
    "\t\t\t\t\"pval\": round(float(inform_reward_policy_p), 3) \n",
    "\t\t\t},\n",
    "\t\t\t\"overall\": {\n",
    "\t\t\t\t\"coeff\": round(float(overall_inform_reward_co), 3), \n",
    "\t\t\t\t\"pval\": round(float(overall_inform_reward_p), 3) \n",
    "\t\t\t},\n",
    "\t\t},\n",
    "\t\t\"human-success_reward\": {\n",
    "\t\t\t\"conv\": {\n",
    "\t\t\t\t\"coeff\": round(float(success_reward_conv_co), 3), \n",
    "\t\t\t\t\"pval\": round(float(success_reward_conv_p), 3)\n",
    "\t\t\t}, \n",
    "\t\t\t\"backend\": {\n",
    "\t\t\t\t\"coeff\": round(float(success_reward_backend_co), 3), \n",
    "\t\t\t\t\"pval\": round(float(success_reward_backend_p), 3) \n",
    "\t\t\t},\n",
    "\t\t\t\"policy\": {\n",
    "\t\t\t\t\"coeff\": round(float(success_reward_policy_co), 3), \n",
    "\t\t\t\t\"pval\": round(float(success_reward_policy_p), 3) \n",
    "\t\t\t},\n",
    "\t\t\t\"overall\": {\n",
    "\t\t\t\t\"coeff\": round(float(overall_success_reward_co), 3), \n",
    "\t\t\t\t\"pval\": round(float(overall_success_reward_p), 3) \n",
    "\t\t\t},\n",
    "\t\t},\n",
    "\t\t\"human-trad_auto\": {\n",
    "\t\t\t\"conv\": {\n",
    "\t\t\t\t\"coeff\": round(float(trad_auto_conv_co), 3), \n",
    "\t\t\t\t\"pval\": round(float(trad_auto_conv_p), 3)\n",
    "\t\t\t}, \n",
    "\t\t\t\"backend\": {\n",
    "\t\t\t\t\"coeff\": round(float(trad_auto_backend_co), 3), \n",
    "\t\t\t\t\"pval\": round(float(trad_auto_backend_p), 3) \n",
    "\t\t\t},\n",
    "\t\t\t\"policy\": {\n",
    "\t\t\t\t\"coeff\": round(float(trad_auto_policy_co), 3), \n",
    "\t\t\t\t\"pval\": round(float(trad_auto_policy_p), 3) \n",
    "\t\t\t},\n",
    "\t\t\t\"overall\": {\n",
    "\t\t\t\t\"coeff\": round(float(overall_trad_auto_co), 3), \n",
    "\t\t\t\t\"pval\": round(float(overall_trad_auto_p), 3) \n",
    "\t\t\t},\n",
    "\t\t}\n",
    "\t}\n",
    "\treturn dial_corrs\n",
    "\n",
    "def compile_all_scores_dial_level(\n",
    "\thuman_batch_scores: dict, \n",
    "\ttdeval_batch_scores: dict, \n",
    "\tlmunit_batch_scores: dict,\n",
    "\ttrad_batch_scores: dict,\n",
    "\ttrad_auto_scores: dict\n",
    "):\n",
    "\tdims = ['conv_consistency', 'backend_consistency', 'policy_completeness']\n",
    "\t# organize scores by batch\n",
    "\tbatch_human_scores = {}\n",
    "\tbatch_tdeval_scores = {}\n",
    "\tbatch_lmunit_scores = {}\n",
    "\tbatch_inform_reward_scores = {}\n",
    "\tbatch_success_reward_scores = {}\n",
    "\tbatch_trad_auto_scores = {}\n",
    "\t# consolidate scores into one large array\n",
    "\tall_human_scores = []\n",
    "\tall_tdeval_scores = []\n",
    "\tall_lmunit_scores = []\n",
    "\tall_inform_reward_scores = []\n",
    "\tall_success_reward_scores = []\n",
    "\tall_trad_auto_scores = []\n",
    "\tfor bId in human_batch_scores.keys():\n",
    "\t\thuman_dials = human_batch_scores[bId][\"dial_level\"]\n",
    "\t\ttdeval_dials = tdeval_batch_scores[bId][\"dial_level\"]\n",
    "\t\tlmunit_dials = lmunit_batch_scores[bId][\"dial_level\"]\n",
    "\t\ttrad_dials = trad_batch_scores[bId]\n",
    "\t\ttrad_auto_dials = trad_auto_scores[bId]\n",
    "\t\tbatch_human_scores[bId] = []\n",
    "\t\tbatch_tdeval_scores[bId] = []\n",
    "\t\tbatch_lmunit_scores[bId] = []\n",
    "\t\tbatch_inform_reward_scores[bId] = []\n",
    "\t\tbatch_success_reward_scores[bId] = []\n",
    "\t\tbatch_trad_auto_scores[bId] = []\n",
    "\t\tfor dId in human_dials.keys():\n",
    "\t\t\thuman_scores = human_dials[dId]\n",
    "\t\t\ttdeval_scores = tdeval_dials[dId]\n",
    "\t\t\tlmunit_score = lmunit_dials[dId]\n",
    "\t\t\ttrad_scores = trad_dials[dId]\n",
    "\t\t\ttrad_auto_score = trad_auto_dials[dId]\n",
    "\t\t\t# batch dial level is just a single score for the whole dialogue\n",
    "\t\t\tbatch_lmunit_scores[bId] = np.append(\n",
    "\t\t\t\tbatch_lmunit_scores[bId], \n",
    "\t\t\t\tlmunit_score\n",
    "\t\t\t)\n",
    "\t\t\tall_lmunit_scores = np.append(\n",
    "\t\t\t\tall_lmunit_scores, \n",
    "\t\t\t\tlmunit_score\n",
    "\t\t\t)\n",
    "\t\t\t# Inform/Success/Tau reward need to be concatenated differently\n",
    "\t\t\tif (\"airline\" not in dId) and (\"retail\" not in dId):\n",
    "\t\t\t\tbatch_inform_reward_scores[bId] = np.append(\n",
    "\t\t\t\t\tbatch_inform_reward_scores[bId], \n",
    "\t\t\t\t\ttrad_scores[\"inform\"]\n",
    "\t\t\t\t)\n",
    "\t\t\t\tall_inform_reward_scores = np.append(\n",
    "\t\t\t\t\tall_inform_reward_scores,\n",
    "\t  \t\t\ttrad_scores[\"inform\"]\n",
    "\t\t\t\t)\n",
    "\t\t\t\tbatch_success_reward_scores[bId] = np.append(\n",
    "\t\t\t\t\tbatch_success_reward_scores[bId],\n",
    "\t\t\t\t\ttrad_scores[\"success\"]\n",
    "\t\t\t\t)\n",
    "\t\t\t\tall_success_reward_scores = np.append(\n",
    "\t\t\t\t\tall_success_reward_scores, \n",
    "\t\t\t\t\ttrad_scores[\"success\"]\n",
    "\t\t\t\t)\n",
    "\t\t\telse:\n",
    "\t\t\t\tbatch_inform_reward_scores[bId] = np.append(\n",
    "\t\t\t\t\tbatch_inform_reward_scores[bId],\n",
    "\t\t\t\t\ttrad_scores\n",
    "\t\t\t\t)\n",
    "\t\t\t\tbatch_success_reward_scores[bId] = np.append(\n",
    "\t\t\t\t\tbatch_success_reward_scores[bId],\n",
    "\t\t\t\t\ttrad_scores\n",
    "\t\t\t\t)\n",
    "\t\t\t\tall_inform_reward_scores = np.append(\n",
    "\t\t\t\t\tall_inform_reward_scores,\n",
    "\t\t\t\t\ttrad_scores\n",
    "\t\t\t\t)\n",
    "\t\t\t\tall_success_reward_scores = np.append(\n",
    "\t\t\t\t\tall_success_reward_scores,\n",
    "\t\t\t\t\ttrad_scores\n",
    "\t\t\t\t)\n",
    "\t\t\t# compile dialogue level automatic metrics, tau and mwoz are same format\n",
    "\t\t\tbatch_trad_auto_scores[bId] = np.append(\n",
    "\t\t\t\tbatch_trad_auto_scores[bId],\n",
    "\t\t\t\ttrad_auto_score\n",
    "\t\t\t)\n",
    "\t\t\tall_trad_auto_scores = np.append(\n",
    "\t\t\t\tall_trad_auto_scores,\n",
    "\t\t\t\ttrad_auto_score\n",
    "\t\t\t)\n",
    "\t\t\tfor metric in dims:\n",
    "\t\t\t\tbatch_human_scores[bId] = np.append(\n",
    "\t\t\t\t\tbatch_human_scores[bId], \n",
    "\t\t\t\t\thuman_scores[metric]\n",
    "\t\t\t\t)\n",
    "\t\t\t\tall_human_scores = np.append(\n",
    "\t\t\t\t\tall_human_scores, \n",
    "\t\t\t\t\thuman_scores[metric]\n",
    "\t\t\t\t)\n",
    "\t\t\t\tbatch_tdeval_scores[bId] = np.append(\n",
    "\t\t\t\t\tbatch_tdeval_scores[bId], \n",
    "\t\t\t\t\ttdeval_scores[metric]\n",
    "\t\t\t\t)\n",
    "\t\t\t\tall_tdeval_scores = np.append(\n",
    "\t\t\t\t\tall_tdeval_scores, \n",
    "\t\t\t\t\ttdeval_scores[metric]\n",
    "\t\t\t\t)\n",
    "\treturn {\n",
    "\t\t'batch': {\n",
    "\t\t\t'human': batch_human_scores,\n",
    "\t\t\t'tdeval': batch_tdeval_scores,\n",
    "\t\t\t'lmunit': batch_lmunit_scores,\n",
    "\t\t\t\"inform_reward\": batch_inform_reward_scores,\n",
    "\t\t\t\"success_reward\": batch_success_reward_scores,\n",
    "\t\t\t\"trad_auto\": batch_trad_auto_scores\n",
    "\t\t},\n",
    "\t\t\"all\": {\n",
    "\t\t\t'human': all_human_scores,\n",
    "\t\t\t'tdeval': all_tdeval_scores,\n",
    "\t\t\t'lmunit': all_lmunit_scores,\n",
    "\t\t\t\"inform_reward\": all_inform_reward_scores,\n",
    "\t\t\t\"success_reward\": all_success_reward_scores,\n",
    "\t\t\t\"trad_auto\": all_trad_auto_scores\n",
    "\t\t}\n",
    "\t}\n",
    "\n",
    "def calculate_dial_level_corrs(\n",
    "\thuman_batch_scores: dict, \n",
    "\ttdeval_batch_scores: dict, \n",
    "\tlmunit_batch_scores: dict,\n",
    "\ttrad_batch_scores: dict,\n",
    "\ttrad_auto_batch_scores: dict\n",
    "):\n",
    "\tcompiled_scores = compile_all_scores_dial_level(\t\n",
    "\t\thuman_batch_scores, \n",
    "\t\ttdeval_batch_scores, \n",
    "\t\tlmunit_batch_scores,\n",
    "\t\ttrad_batch_scores,\n",
    "\t\ttrad_auto_batch_scores\n",
    "\t)\n",
    "\t# serialize batched compile scores\n",
    "\tbatch_human_scores = compiled_scores['batch']['human']\n",
    "\tbatch_tdeval_scores = compiled_scores['batch']['tdeval']\n",
    "\tbatch_lmunit_scores = compiled_scores['batch']['lmunit']\n",
    "\tbatch_inform_reward_scores = compiled_scores['batch']['inform_reward']\n",
    "\tbatch_success_reward_scores = compiled_scores['batch']['success_reward']\n",
    "\tbatch_trad_auto_scores = compiled_scores['batch']['trad_auto']\n",
    "\t# serialized fully compiled scores\n",
    "\tall_human_scores = compiled_scores['all']['human']\n",
    "\tall_tdeval_scores = compiled_scores['all']['tdeval']\n",
    "\tall_lmunit_scores = compiled_scores['all']['lmunit']\n",
    "\tall_inform_reward_scores = compiled_scores['all']['inform_reward']\n",
    "\tall_success_reward_scores = compiled_scores['all']['success_reward']\n",
    "\tall_trad_auto_scores = compiled_scores['all']['trad_auto']\n",
    "\t# take correlation for each batch\n",
    "\tdial_corrs = {}\n",
    "\tfor bId in human_batch_scores.keys():\n",
    "\t\tdial_corrs[bId] = map_all_correlations_dial_level(\n",
    "\t\t\tbatch_human_scores[bId], \n",
    "\t\t\tbatch_tdeval_scores[bId], \n",
    "\t\t\tbatch_lmunit_scores[bId], \n",
    "\t\t\tbatch_inform_reward_scores[bId], \n",
    "\t\t\tbatch_success_reward_scores[bId],\n",
    "\t\t\tbatch_trad_auto_scores[bId]\n",
    "\t\t)\n",
    "\tdial_corrs[\"all\"] = map_all_correlations_dial_level(\n",
    "\t\tall_human_scores,\n",
    "\t\tall_tdeval_scores,\n",
    "\t\tall_lmunit_scores,\n",
    "\t\tall_inform_reward_scores,\n",
    "\t\tall_success_reward_scores,\n",
    "\t\tall_trad_auto_scores\n",
    "\t)\n",
    "\treturn dial_corrs\n",
    "\n",
    "dial_level_corr = calculate_dial_level_corrs(\n",
    "\thuman_batch_scores, \n",
    "\ttdeval_batch_scores, \n",
    "\tlmunit_batch_scores,\n",
    "\ttrad_batch_scores,\n",
    "\ttrad_auto_batch_scores\n",
    ")\n",
    "pprint.pprint(dial_level_corr[\"all\"], compact=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "633433e9",
   "metadata": {},
   "source": [
    "#### Calculate Dialogue-Level IRR: Human vs TD-Eval, LMUnit, AutoTOD, Inform/Success + Tau Reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba607a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_all_irr_dial_level(\n",
    "\thuman_scores: np.ndarray, \n",
    "\ttdeval_scores: np.ndarray, \n",
    "\tlmunit_scores: np.ndarray, \n",
    "\tinform_reward_scores: np.ndarray, \n",
    "\tsuccess_reward_scores: np.ndarray, \n",
    "\ttrad_auto_scores: np.ndarray\n",
    "):\n",
    "\t# take IRR by metric (conv)\n",
    "\thuman_conv = human_scores[::3]\n",
    "\tbin_human_conv = np.where(human_conv >= 4, 1, 0)\n",
    "\ttdeval_conv = tdeval_scores[::3]\n",
    "\n",
    "\thuman_tdeval_conv = np.vstack(\n",
    "\t\t(human_conv, tdeval_conv)\n",
    "\t).astype(dtype=np.int64)\n",
    "\thuman_tdeval_conv_gwet = calculate_gwet_ac(human_tdeval_conv)\n",
    "\thuman_tdeval_conv_kappa = calculate_kappa(\n",
    "\t\thuman_tdeval_conv-1, \n",
    "\t\tn_cat=5\n",
    "\t)['randolph']\n",
    "\n",
    "\thuman_lmunit_conv = np.vstack(\n",
    "\t\t(human_conv, lmunit_scores)\n",
    "\t).astype(dtype=np.int64)\n",
    "\thuman_lmunit_conv_gwet = calculate_gwet_ac(human_lmunit_conv)\n",
    "\thuman_lmunit_conv_kappa = calculate_kappa(\n",
    "\t\thuman_lmunit_conv-1, \n",
    "\t\tn_cat=5\n",
    "\t)['randolph']\n",
    "\n",
    "\thuman_inform_reward_conv = np.vstack(\n",
    "\t\t(bin_human_conv, inform_reward_scores)\n",
    "\t).astype(dtype=np.int64)\n",
    "\thuman_inform_reward_conv_gwet = calculate_gwet_ac(human_inform_reward_conv)\n",
    "\thuman_inform_reward_conv_kappa = calculate_kappa(\n",
    "\t\thuman_inform_reward_conv, \n",
    "\t\tn_cat=2\n",
    "\t)['randolph']\n",
    "\n",
    "\thuman_success_reward_conv = np.vstack(\n",
    "\t\t(bin_human_conv, success_reward_scores)\n",
    "\t).astype(dtype=np.int64)\n",
    "\thuman_success_reward_conv_gwet = calculate_gwet_ac(human_success_reward_conv)\n",
    "\thuman_success_reward_conv_kappa = calculate_kappa(\n",
    "\t\thuman_success_reward_conv, \n",
    "\t\tn_cat=2\n",
    "\t)['randolph']\n",
    "\n",
    "\thuman_trad_auto_conv = np.vstack(\n",
    "\t\t(bin_human_conv, trad_auto_scores)\n",
    "\t).astype(dtype=np.int64)\n",
    "\thuman_trad_auto_conv_gwet = calculate_gwet_ac(human_trad_auto_conv)\n",
    "\thuman_trad_auto_conv_kappa = calculate_kappa(\n",
    "\t\thuman_trad_auto_conv, \n",
    "\t\tn_cat=2\n",
    "\t)['randolph']\n",
    "\n",
    "\t# take correlation by metric (backend)\n",
    "\thuman_backend = human_scores[1::3]\n",
    "\tbin_human_backend = np.where(human_backend >= 4, 1, 0)\n",
    "\ttdeval_backend = tdeval_scores[1::3]\n",
    "\thuman_tdeval_backend = np.vstack(\n",
    "\t\t(human_backend, tdeval_backend)\n",
    "\t).astype(dtype=np.int64)\n",
    "\thuman_tdeval_backend_gwet = calculate_gwet_ac(human_tdeval_backend)\n",
    "\thuman_tdeval_backend_kappa = calculate_kappa(\n",
    "\t\thuman_tdeval_backend-1, \n",
    "\t\tn_cat=5\n",
    "\t)['randolph']\n",
    "\n",
    "\thuman_lmunit_backend = np.vstack(\n",
    "\t\t(human_backend, lmunit_scores)\n",
    "\t).astype(dtype=np.int64)\n",
    "\thuman_lmunit_backend_gwet = calculate_gwet_ac(human_lmunit_backend)\n",
    "\thuman_lmunit_backend_kappa = calculate_kappa(\n",
    "\t\thuman_lmunit_backend-1, \n",
    "\t\tn_cat=5\n",
    "\t)['randolph']\n",
    "\n",
    "\thuman_inform_reward_backend = np.vstack(\n",
    "\t\t(bin_human_backend, inform_reward_scores)\n",
    "\t).astype(dtype=np.int64)\n",
    "\thuman_inform_reward_backend_gwet = calculate_gwet_ac(\n",
    "\t\thuman_inform_reward_backend\n",
    "\t)\n",
    "\thuman_inform_reward_backend_kappa = calculate_kappa(\n",
    "\t\thuman_inform_reward_backend, \n",
    "\t\tn_cat=2\n",
    "\t)['randolph']\n",
    "\n",
    "\thuman_success_reward_backend = np.vstack(\n",
    "\t\t(bin_human_backend, success_reward_scores)\n",
    "\t).astype(dtype=np.int64)\n",
    "\thuman_success_reward_backend_gwet = calculate_gwet_ac(\n",
    "\t\thuman_success_reward_backend\n",
    "\t)\n",
    "\thuman_success_reward_backend_kappa = calculate_kappa(\n",
    "\t\thuman_success_reward_backend, \n",
    "\t\tn_cat=2\n",
    "\t)['randolph']\n",
    "\n",
    "\thuman_trad_auto_backend = np.vstack(\n",
    "\t\t(bin_human_backend, trad_auto_scores)\n",
    "\t).astype(dtype=np.int64)\n",
    "\thuman_trad_auto_backend_gwet = calculate_gwet_ac(human_trad_auto_backend)\n",
    "\thuman_trad_auto_backend_kappa = calculate_kappa(\n",
    "\t\thuman_trad_auto_backend, \n",
    "\t\tn_cat=2\n",
    "\t)['randolph']\n",
    "\n",
    "\t# take correlation by metric (policy)\n",
    "\thuman_policy = human_scores[2::3]\n",
    "\tbin_human_policy = np.where(human_policy >= 4, 1, 0)\n",
    "\ttdeval_policy = tdeval_scores[2::3]\n",
    "\t\n",
    "\thuman_tdeval_policy = np.vstack(\n",
    "\t\t(human_policy, tdeval_policy)\n",
    "\t).astype(dtype=np.int64)\n",
    "\thuman_tdeval_policy_gwet = calculate_gwet_ac(human_tdeval_policy)\n",
    "\thuman_tdeval_policy_kappa = calculate_kappa(\n",
    "\t\thuman_tdeval_policy-1, \n",
    "\t\tn_cat=5\n",
    "\t)['randolph']\n",
    "\n",
    "\thuman_lmunit_policy = np.vstack(\n",
    "\t\t(human_policy, lmunit_scores)\n",
    "\t).astype(dtype=np.int64)\n",
    "\thuman_lmunit_policy_gwet = calculate_gwet_ac(human_lmunit_policy)\n",
    "\thuman_lmunit_policy_kappa = calculate_kappa(\n",
    "\t\thuman_lmunit_policy-1, \n",
    "\t\tn_cat=5\n",
    "\t)['randolph']\n",
    "\n",
    "\thuman_inform_reward_policy = np.vstack(\n",
    "\t\t(bin_human_policy, inform_reward_scores)\n",
    "\t).astype(dtype=np.int64)\n",
    "\thuman_inform_reward_policy_gwet = calculate_gwet_ac(\n",
    "\t\thuman_inform_reward_policy\n",
    "\t)\n",
    "\thuman_inform_reward_policy_kappa = calculate_kappa(\n",
    "\t\thuman_inform_reward_policy, \n",
    "\t\tn_cat=2\n",
    "\t)['randolph']\n",
    "\n",
    "\thuman_success_reward_policy = np.vstack(\n",
    "\t\t(bin_human_policy, success_reward_scores)\n",
    "\t).astype(dtype=np.int64)\n",
    "\thuman_success_reward_policy_gwet = calculate_gwet_ac(\n",
    "\t\thuman_success_reward_policy\n",
    "\t)\n",
    "\thuman_success_reward_kappa = calculate_kappa(\n",
    "\t\thuman_success_reward_policy, \n",
    "\t\tn_cat=2\n",
    "\t)['randolph']\n",
    "\n",
    "\thuman_trad_auto_policy = np.vstack(\n",
    "\t\t(bin_human_policy, trad_auto_scores)\n",
    "\t).astype(dtype=np.int64)\n",
    "\thuman_trad_auto_policy_gwet = calculate_gwet_ac(human_trad_auto_policy)\n",
    "\thuman_trad_auto_policy_kappa = calculate_kappa(\n",
    "\t\thuman_trad_auto_policy, \n",
    "\t\tn_cat=2\n",
    "\t)['randolph']\n",
    "\n",
    "\t# take correlation of all metrics (overall)\n",
    "\toverall_human = human_scores\n",
    "\tavg_human = np.mean(human_scores.reshape((-1, 3)), axis=1)\n",
    "\tavg_bin_human = np.where(avg_human >= 4, 1, 0)\n",
    "\toverall_tdeval = tdeval_scores\n",
    "\n",
    "\toverall_human_tdeval = np.vstack(\n",
    "\t\t(overall_human, overall_tdeval)\n",
    "\t).astype(dtype=np.int64)\n",
    "\toverall_human_tdeval_gwet = calculate_gwet_ac(overall_human_tdeval)\n",
    "\toverall_human_tdeval_kappa = calculate_kappa(\n",
    "\t\toverall_human_tdeval-1, \n",
    "\t\t5\n",
    "\t)['randolph']\n",
    "\n",
    "\toverall_human_lmunit = np.vstack(\n",
    "\t\t(avg_human, lmunit_scores)\n",
    "\t).astype(dtype=np.int64)\n",
    "\toverall_human_lmunit_gwet = calculate_gwet_ac(overall_human_lmunit)\n",
    "\toverall_human_lmunit_kappa = calculate_kappa(\n",
    "\t\toverall_human_lmunit-1,\n",
    "\t\tn_cat=5\n",
    "\t)['randolph']\n",
    "\n",
    "\toverall_human_inform_reward = np.vstack(\n",
    "\t\t(avg_bin_human, inform_reward_scores)\n",
    "\t).astype(dtype=np.int64)\n",
    "\toverall_human_inform_reward_gwet = calculate_gwet_ac(\n",
    "\t\toverall_human_inform_reward\n",
    "\t)\n",
    "\toverall_human_inform_reward_kappa = calculate_kappa(\n",
    "\t\toverall_human_inform_reward, \n",
    "\t\tn_cat=2\n",
    "\t)['randolph']\n",
    "\n",
    "\toverall_human_success_reward = np.vstack(\n",
    "\t\t(avg_bin_human, success_reward_scores)\n",
    "\t).astype(dtype=np.int64)\n",
    "\toverall_human_success_reward_gwet = calculate_gwet_ac(\n",
    "\t\toverall_human_success_reward\n",
    "\t)\n",
    "\toverall_human_success_reward_kappa = calculate_kappa(\n",
    "\t\toverall_human_success_reward, \n",
    "\t\tn_cat=2\n",
    "\t)['randolph']\n",
    "\n",
    "\toverall_human_trad_auto = np.vstack(\n",
    "\t\t(avg_bin_human, trad_auto_scores)\n",
    "\t).astype(dtype=np.int64)\n",
    "\toverall_human_trad_auto_gwet = calculate_gwet_ac(overall_human_trad_auto)\n",
    "\toverall_human_trad_auto_kappa = calculate_kappa(\n",
    "\t\toverall_human_trad_auto, \n",
    "\t\tn_cat=2\n",
    "\t)['randolph']\n",
    "\n",
    "\tdial_irr = {\n",
    "\t\t\"human-tdeval\": {\n",
    "\t\t\t\"conv\": {\n",
    "\t\t\t\t\"gwet-ac1\": human_tdeval_conv_gwet,\n",
    "\t\t\t\t\"r_kappa\": human_tdeval_conv_kappa\n",
    "\t\t\t}, \n",
    "\t\t\t\"backend\": {\n",
    "\t\t\t\t\"gwet-ac1\": human_tdeval_backend_gwet,\n",
    "\t\t\t\t\"r_kappa\": human_tdeval_backend_kappa\n",
    "\t\t\t},\n",
    "\t\t\t\"policy\": {\n",
    "\t\t\t\t\"gwet-ac1\": human_tdeval_policy_gwet,\n",
    "\t\t\t\t\"r_kappa\": human_tdeval_policy_kappa\n",
    "\t\t\t},\n",
    "\t\t\t\"overall\": {\n",
    "\t\t\t\t\"gwet-ac1\": overall_human_tdeval_gwet,\n",
    "\t\t\t\t\"r_kappa\": overall_human_tdeval_kappa\n",
    "\t\t\t},\n",
    "\t\t},\n",
    "\t\t\"human-lmunit\": {\n",
    "\t\t\t\"conv\": {\n",
    "\t\t\t\t\"gwet-ac1\": human_lmunit_conv_gwet,\n",
    "\t\t\t\t\"r_kappa\": human_lmunit_conv_kappa\n",
    "\t\t\t},\n",
    "\t\t\t\"backend\": {\n",
    "\t\t\t\t\"gwet-ac1\": human_lmunit_backend_gwet,\n",
    "\t\t\t\t\"r_kappa\": human_lmunit_backend_kappa\n",
    "\t\t\t},\n",
    "\t\t\t\"policy\": {\n",
    "\t\t\t\t\"gwet-ac1\": human_lmunit_policy_gwet,\n",
    "\t\t\t\t\"r_kappa\": human_lmunit_policy_kappa\n",
    "\t\t\t},\n",
    "\t\t\t\"overall\": {\n",
    "\t\t\t\t\"gwet-ac1\": overall_human_lmunit_gwet,\n",
    "\t\t\t\t\"r_kappa\": overall_human_lmunit_kappa\n",
    "\t\t\t},\n",
    "\t\t},\n",
    "\t\t\"human-inform-reward\": {\n",
    "\t\t\t\"conv\": {\n",
    "\t\t\t\t\"gwet-ac1\": human_inform_reward_conv_gwet,\n",
    "\t\t\t\t\"r_kappa\": human_inform_reward_conv_kappa\n",
    "\t\t\t},\n",
    "\t\t\t\"backend\": {\n",
    "\t\t\t\t\"gwet-ac1\": human_inform_reward_backend_gwet,\n",
    "\t\t\t\t\"r_kappa\": human_inform_reward_backend_kappa\n",
    "\t\t\t},\n",
    "\t\t\t\"policy\": {\n",
    "\t\t\t\t\"gwet-ac1\": human_inform_reward_policy_gwet,\n",
    "\t\t\t\t\"r_kappa\": human_inform_reward_policy_kappa\n",
    "\t\t\t},\n",
    "\t\t\t\"overall\": {\n",
    "\t\t\t\t\"gwet-ac1\": overall_human_inform_reward_gwet,\n",
    "\t\t\t\t\"r_kappa\": overall_human_inform_reward_kappa\n",
    "\t\t\t},\n",
    "\t\t},\n",
    "\t\t\"human-success-reward\": {\n",
    "\t\t\t\"conv\": {\n",
    "\t\t\t\t\"gwet-ac1\": human_success_reward_conv_gwet,\n",
    "\t\t\t\t\"r_kappa\": human_success_reward_conv_kappa\n",
    "\t\t\t},\n",
    "\t\t\t\"backend\": {\n",
    "\t\t\t\t\"gwet-ac1\": human_success_reward_backend_gwet,\n",
    "\t\t\t\t\"r_kappa\": human_success_reward_backend_kappa\n",
    "\t\t\t},\n",
    "\t\t\t\"policy\": {\n",
    "\t\t\t\t\"gwet-ac1\": human_success_reward_policy_gwet,\n",
    "\t\t\t\t\"r_kappa\": human_success_reward_kappa\n",
    "\t\t\t},\n",
    "\t\t\t\"overall\": {\n",
    "\t\t\t\t\"gwet-ac1\": overall_human_success_reward_gwet,\n",
    "\t\t\t\t\"r_kappa\": overall_human_success_reward_kappa\n",
    "\t\t\t},\n",
    "\t\t},\n",
    "\t\t\"human-trad-auto\": {\n",
    "\t\t\t\"conv\": {\n",
    "\t\t\t\t\"gwet-ac1\": human_trad_auto_conv_gwet,\n",
    "\t\t\t\t\"r_kappa\": human_trad_auto_conv_kappa\n",
    "\t\t\t},\n",
    "\t\t\t\"backend\": {\n",
    "\t\t\t\t\"gwet-ac1\": human_trad_auto_backend_gwet,\n",
    "\t\t\t\t\"r_kappa\": human_trad_auto_backend_kappa\n",
    "\t\t\t},\n",
    "\t\t\t\"policy\": {\n",
    "\t\t\t\t\"gwet-ac1\": human_trad_auto_policy_gwet,\n",
    "\t\t\t\t\"r_kappa\": human_trad_auto_policy_kappa\n",
    "\t\t\t},\n",
    "\t\t\t\"overall\": {\n",
    "\t\t\t\t\"gwet-ac1\": overall_human_trad_auto_gwet,\n",
    "\t\t\t\t\"r_kappa\": overall_human_trad_auto_kappa\n",
    "\t\t\t}\n",
    "\t\t}\n",
    "\t}\n",
    "\treturn dial_irr\n",
    "\n",
    "def calculate_dial_level_agreement(\n",
    "\thuman_batch_scores: dict, \n",
    "\ttdeval_batch_scores: dict, \n",
    "\tlmunit_batch_scores: dict,\n",
    "\ttrad_batch_scores: dict,\n",
    "\ttrad_auto_batch_scores: dict\n",
    "):\n",
    "\tcompiled_scores = compile_all_scores_dial_level(\t\n",
    "\t\thuman_batch_scores, \n",
    "\t\ttdeval_batch_scores, \n",
    "\t\tlmunit_batch_scores,\n",
    "\t\ttrad_batch_scores,\n",
    "\t\ttrad_auto_batch_scores\n",
    "\t)\n",
    "\t# serialize batched compile scores\n",
    "\tbatch_human_scores = compiled_scores['batch']['human']\n",
    "\tbatch_tdeval_scores = compiled_scores['batch']['tdeval']\n",
    "\tbatch_lmunit_scores = compiled_scores['batch']['lmunit']\n",
    "\tbatch_inform_reward_scores = compiled_scores['batch']['inform_reward']\n",
    "\tbatch_success_reward_scores = compiled_scores['batch']['success_reward']\n",
    "\tbatch_trad_auto_scores = compiled_scores['batch']['trad_auto']\n",
    "\t# serialized fully compiled scores\n",
    "\tall_human_scores = compiled_scores['all']['human']\n",
    "\tall_tdeval_scores = compiled_scores['all']['tdeval']\n",
    "\tall_lmunit_scores = compiled_scores['all']['lmunit']\n",
    "\tall_inform_reward_scores = compiled_scores['all']['inform_reward']\n",
    "\tall_success_reward_scores = compiled_scores['all']['success_reward']\n",
    "\tall_trad_auto_scores = compiled_scores['all']['trad_auto']\n",
    "\t# take IRR for each batch\n",
    "\tdial_irr = {}\n",
    "\tfor bId in human_batch_scores.keys():\n",
    "\t\tdial_irr[bId] = map_all_irr_dial_level(\n",
    "\t\t\tbatch_human_scores[bId], \n",
    "\t\t\tbatch_tdeval_scores[bId], \n",
    "\t\t\tbatch_lmunit_scores[bId], \n",
    "\t\t\tbatch_inform_reward_scores[bId], \n",
    "\t\t\tbatch_success_reward_scores[bId],\n",
    "\t\t\tbatch_trad_auto_scores[bId]\n",
    "\t\t)\n",
    "\tdial_irr[\"all\"] = map_all_irr_dial_level(\n",
    "\t\tall_human_scores,\n",
    "\t\tall_tdeval_scores,\n",
    "\t\tall_lmunit_scores,\n",
    "\t\tall_inform_reward_scores,\n",
    "\t\tall_success_reward_scores,\n",
    "\t\tall_trad_auto_scores\n",
    "\t)\n",
    "\treturn dial_irr\n",
    "\n",
    "dial_level_irr = calculate_dial_level_agreement(\n",
    "\thuman_batch_scores, \n",
    "\ttdeval_batch_scores, \n",
    "\tlmunit_batch_scores,\n",
    "\ttrad_batch_scores,\n",
    "\ttrad_auto_batch_scores\n",
    ")\n",
    "pprint.pprint(dial_level_irr[\"all\"], compact=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faed8917",
   "metadata": {},
   "source": [
    "#### Find agreement only on MultiWOZ dialogues on traditional automatic metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe88280e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_all_irr_mwoz_dial_level(\n",
    "\thuman_scores: np.ndarray, \n",
    "\ttdeval_scores: np.ndarray, \n",
    "\tlmunit_scores: np.ndarray, \n",
    "\tinform_scores: np.ndarray, \n",
    "\tsuccess_scores: np.ndarray, \n",
    "\ttrad_auto_scores: np.ndarray\n",
    "):\n",
    "\t# take IRR by metric (conv)\n",
    "\thuman_conv = human_scores[::3]\n",
    "\tbin_human_conv = np.where(human_conv >= 4, 1, 0)\n",
    "\ttdeval_conv = tdeval_scores[::3]\n",
    "\n",
    "\thuman_tdeval_conv = np.vstack(\n",
    "\t\t(human_conv, tdeval_conv)\n",
    "\t).astype(dtype=np.int64)\n",
    "\thuman_tdeval_conv_gwet = calculate_gwet_ac(human_tdeval_conv)\n",
    "\thuman_tdeval_conv_kappa = calculate_kappa(\n",
    "\t\thuman_tdeval_conv-1, \n",
    "\t\tn_cat=5\n",
    "\t)['randolph']\n",
    "\n",
    "\thuman_lmunit_conv = np.vstack(\n",
    "\t\t(human_conv, lmunit_scores)\n",
    "\t).astype(dtype=np.int64)\n",
    "\thuman_lmunit_conv_gwet = calculate_gwet_ac(human_lmunit_conv)\n",
    "\thuman_lmunit_conv_kappa = calculate_kappa(\n",
    "\t\thuman_lmunit_conv-1, \n",
    "\t\tn_cat=5\n",
    "\t)['randolph']\n",
    "\n",
    "\thuman_inform_conv = np.vstack(\n",
    "\t\t(bin_human_conv, inform_scores)\n",
    "\t).astype(dtype=np.int64)\n",
    "\thuman_inform_conv_gwet = calculate_gwet_ac(human_inform_conv)\n",
    "\thuman_inform_conv_kappa = calculate_kappa(\n",
    "\t\thuman_inform_conv, \n",
    "\t\tn_cat=2\n",
    "\t)['randolph']\n",
    "\n",
    "\thuman_success_conv = np.vstack(\n",
    "\t\t(bin_human_conv, success_scores)\n",
    "\t).astype(dtype=np.int64)\n",
    "\thuman_success_conv_gwet = calculate_gwet_ac(human_success_conv)\n",
    "\thuman_success_conv_kappa = calculate_kappa(\n",
    "\t\thuman_success_conv, \n",
    "\t\tn_cat=2\n",
    "\t)['randolph']\n",
    "\n",
    "\thuman_trad_auto_conv = np.vstack(\n",
    "\t\t(bin_human_conv, trad_auto_scores)\n",
    "\t).astype(dtype=np.int64)\n",
    "\thuman_trad_auto_conv_gwet = calculate_gwet_ac(human_trad_auto_conv)\n",
    "\thuman_trad_auto_conv_kappa = calculate_kappa(\n",
    "\t\thuman_trad_auto_conv, \n",
    "\t\tn_cat=2\n",
    "\t)['randolph']\n",
    "\n",
    "\t# take correlation by metric (backend)\n",
    "\thuman_backend = human_scores[1::3]\n",
    "\tbin_human_backend = np.where(human_backend >= 4, 1, 0)\n",
    "\ttdeval_backend = tdeval_scores[1::3]\n",
    "\thuman_tdeval_backend = np.vstack(\n",
    "\t\t(human_backend, tdeval_backend)\n",
    "\t).astype(dtype=np.int64)\n",
    "\thuman_tdeval_backend_gwet = calculate_gwet_ac(human_tdeval_backend)\n",
    "\thuman_tdeval_backend_kappa = calculate_kappa(\n",
    "\t\thuman_tdeval_backend-1, \n",
    "\t\tn_cat=5\n",
    "\t)['randolph']\n",
    "\n",
    "\thuman_lmunit_backend = np.vstack(\n",
    "\t\t(human_backend, lmunit_scores)\n",
    "\t).astype(dtype=np.int64)\n",
    "\thuman_lmunit_backend_gwet = calculate_gwet_ac(human_lmunit_backend)\n",
    "\thuman_lmunit_backend_kappa = calculate_kappa(\n",
    "\t\thuman_lmunit_backend-1, \n",
    "\t\tn_cat=5\n",
    "\t)['randolph']\n",
    "\n",
    "\thuman_inform_backend = np.vstack(\n",
    "\t\t(bin_human_backend, inform_scores)\n",
    "\t).astype(dtype=np.int64)\n",
    "\thuman_inform_backend_gwet = calculate_gwet_ac(\n",
    "\t\thuman_inform_backend\n",
    "\t)\n",
    "\thuman_inform_backend_kappa = calculate_kappa(\n",
    "\t\thuman_inform_backend, \n",
    "\t\tn_cat=2\n",
    "\t)['randolph']\n",
    "\n",
    "\thuman_success_backend = np.vstack(\n",
    "\t\t(bin_human_backend, success_scores)\n",
    "\t).astype(dtype=np.int64)\n",
    "\thuman_success_backend_gwet = calculate_gwet_ac(\n",
    "\t\thuman_success_backend\n",
    "\t)\n",
    "\thuman_success_backend_kappa = calculate_kappa(\n",
    "\t\thuman_success_backend, \n",
    "\t\tn_cat=2\n",
    "\t)['randolph']\n",
    "\n",
    "\thuman_trad_auto_backend = np.vstack(\n",
    "\t\t(bin_human_backend, trad_auto_scores)\n",
    "\t).astype(dtype=np.int64)\n",
    "\thuman_trad_auto_backend_gwet = calculate_gwet_ac(human_trad_auto_backend)\n",
    "\thuman_trad_auto_backend_kappa = calculate_kappa(\n",
    "\t\thuman_trad_auto_backend, \n",
    "\t\tn_cat=2\n",
    "\t)['randolph']\n",
    "\n",
    "\t# take correlation by metric (policy)\n",
    "\thuman_policy = human_scores[2::3]\n",
    "\tbin_human_policy = np.where(human_policy >= 4, 1, 0)\n",
    "\ttdeval_policy = tdeval_scores[2::3]\n",
    "\t\n",
    "\thuman_tdeval_policy = np.vstack(\n",
    "\t\t(human_policy, tdeval_policy)\n",
    "\t).astype(dtype=np.int64)\n",
    "\thuman_tdeval_policy_gwet = calculate_gwet_ac(human_tdeval_policy)\n",
    "\thuman_tdeval_policy_kappa = calculate_kappa(\n",
    "\t\thuman_tdeval_policy-1, \n",
    "\t\tn_cat=5\n",
    "\t)['randolph']\n",
    "\n",
    "\thuman_lmunit_policy = np.vstack(\n",
    "\t\t(human_policy, lmunit_scores)\n",
    "\t).astype(dtype=np.int64)\n",
    "\thuman_lmunit_policy_gwet = calculate_gwet_ac(human_lmunit_policy)\n",
    "\thuman_lmunit_policy_kappa = calculate_kappa(\n",
    "\t\thuman_lmunit_policy-1, \n",
    "\t\tn_cat=5\n",
    "\t)['randolph']\n",
    "\n",
    "\thuman_inform_policy = np.vstack(\n",
    "\t\t(bin_human_policy, inform_scores)\n",
    "\t).astype(dtype=np.int64)\n",
    "\thuman_inform_policy_gwet = calculate_gwet_ac(\n",
    "\t\thuman_inform_policy\n",
    "\t)\n",
    "\thuman_inform_policy_kappa = calculate_kappa(\n",
    "\t\thuman_inform_policy, \n",
    "\t\tn_cat=2\n",
    "\t)['randolph']\n",
    "\n",
    "\thuman_success_policy = np.vstack(\n",
    "\t\t(bin_human_policy, success_scores)\n",
    "\t).astype(dtype=np.int64)\n",
    "\thuman_success_policy_gwet = calculate_gwet_ac(\n",
    "\t\thuman_success_policy\n",
    "\t)\n",
    "\thuman_success_kappa = calculate_kappa(\n",
    "\t\thuman_success_policy, \n",
    "\t\tn_cat=2\n",
    "\t)['randolph']\n",
    "\n",
    "\thuman_trad_auto_policy = np.vstack(\n",
    "\t\t(bin_human_policy, trad_auto_scores)\n",
    "\t).astype(dtype=np.int64)\n",
    "\thuman_trad_auto_policy_gwet = calculate_gwet_ac(human_trad_auto_policy)\n",
    "\thuman_trad_auto_policy_kappa = calculate_kappa(\n",
    "\t\thuman_trad_auto_policy, \n",
    "\t\tn_cat=2\n",
    "\t)['randolph']\n",
    "\n",
    "\t# take correlation of all metrics (overall)\n",
    "\toverall_human = human_scores\n",
    "\tavg_human = np.mean(human_scores.reshape((-1, 3)), axis=1)\n",
    "\tavg_bin_human = np.where(avg_human >= 4, 1, 0)\n",
    "\toverall_tdeval = tdeval_scores\n",
    "\n",
    "\toverall_human_tdeval = np.vstack(\n",
    "\t\t(overall_human, overall_tdeval)\n",
    "\t).astype(dtype=np.int64)\n",
    "\toverall_human_tdeval_gwet = calculate_gwet_ac(overall_human_tdeval)\n",
    "\toverall_human_tdeval_kappa = calculate_kappa(\n",
    "\t\toverall_human_tdeval-1, \n",
    "\t\t5\n",
    "\t)['randolph']\n",
    "\n",
    "\toverall_human_lmunit = np.vstack(\n",
    "\t\t(avg_human, lmunit_scores)\n",
    "\t).astype(dtype=np.int64)\n",
    "\toverall_human_lmunit_gwet = calculate_gwet_ac(overall_human_lmunit)\n",
    "\toverall_human_lmunit_kappa = calculate_kappa(\n",
    "\t\toverall_human_lmunit-1,\n",
    "\t\tn_cat=5\n",
    "\t)['randolph']\n",
    "\n",
    "\toverall_human_inform = np.vstack(\n",
    "\t\t(avg_bin_human, inform_scores)\n",
    "\t).astype(dtype=np.int64)\n",
    "\toverall_human_inform_gwet = calculate_gwet_ac(\n",
    "\t\toverall_human_inform\n",
    "\t)\n",
    "\toverall_human_inform_kappa = calculate_kappa(\n",
    "\t\toverall_human_inform, \n",
    "\t\tn_cat=2\n",
    "\t)['randolph']\n",
    "\n",
    "\toverall_human_success = np.vstack(\n",
    "\t\t(avg_bin_human, success_scores)\n",
    "\t).astype(dtype=np.int64)\n",
    "\toverall_human_success_gwet = calculate_gwet_ac(\n",
    "\t\toverall_human_success\n",
    "\t)\n",
    "\toverall_human_success_kappa = calculate_kappa(\n",
    "\t\toverall_human_success, \n",
    "\t\tn_cat=2\n",
    "\t)['randolph']\n",
    "\n",
    "\toverall_human_trad_auto = np.vstack(\n",
    "\t\t(avg_bin_human, trad_auto_scores)\n",
    "\t).astype(dtype=np.int64)\n",
    "\toverall_human_trad_auto_gwet = calculate_gwet_ac(overall_human_trad_auto)\n",
    "\toverall_human_trad_auto_kappa = calculate_kappa(\n",
    "\t\toverall_human_trad_auto, \n",
    "\t\tn_cat=2\n",
    "\t)['randolph']\n",
    "\n",
    "\tdial_irr = {\n",
    "\t\t\"mwoz-human-tdeval\": {\n",
    "\t\t\t\"conv\": {\n",
    "\t\t\t\t\"gwet-ac1\": human_tdeval_conv_gwet,\n",
    "\t\t\t\t\"r_kappa\": human_tdeval_conv_kappa\n",
    "\t\t\t}, \n",
    "\t\t\t\"backend\": {\n",
    "\t\t\t\t\"gwet-ac1\": human_tdeval_backend_gwet,\n",
    "\t\t\t\t\"r_kappa\": human_tdeval_backend_kappa\n",
    "\t\t\t},\n",
    "\t\t\t\"policy\": {\n",
    "\t\t\t\t\"gwet-ac1\": human_tdeval_policy_gwet,\n",
    "\t\t\t\t\"r_kappa\": human_tdeval_policy_kappa\n",
    "\t\t\t},\n",
    "\t\t\t\"overall\": {\n",
    "\t\t\t\t\"gwet-ac1\": overall_human_tdeval_gwet,\n",
    "\t\t\t\t\"r_kappa\": overall_human_tdeval_kappa\n",
    "\t\t\t},\n",
    "\t\t},\n",
    "\t\t\"mwoz-human-lmunit\": {\n",
    "\t\t\t\"conv\": {\n",
    "\t\t\t\t\"gwet-ac1\": human_lmunit_conv_gwet,\n",
    "\t\t\t\t\"r_kappa\": human_lmunit_conv_kappa\n",
    "\t\t\t},\n",
    "\t\t\t\"backend\": {\n",
    "\t\t\t\t\"gwet-ac1\": human_lmunit_backend_gwet,\n",
    "\t\t\t\t\"r_kappa\": human_lmunit_backend_kappa\n",
    "\t\t\t},\n",
    "\t\t\t\"policy\": {\n",
    "\t\t\t\t\"gwet-ac1\": human_lmunit_policy_gwet,\n",
    "\t\t\t\t\"r_kappa\": human_lmunit_policy_kappa\n",
    "\t\t\t},\n",
    "\t\t\t\"overall\": {\n",
    "\t\t\t\t\"gwet-ac1\": overall_human_lmunit_gwet,\n",
    "\t\t\t\t\"r_kappa\": overall_human_lmunit_kappa\n",
    "\t\t\t},\n",
    "\t\t},\n",
    "\t\t\"mwoz-human-inform\": {\n",
    "\t\t\t\"conv\": {\n",
    "\t\t\t\t\"gwet-ac1\": human_inform_conv_gwet,\n",
    "\t\t\t\t\"r_kappa\": human_inform_conv_kappa\n",
    "\t\t\t},\n",
    "\t\t\t\"backend\": {\n",
    "\t\t\t\t\"gwet-ac1\": human_inform_backend_gwet,\n",
    "\t\t\t\t\"r_kappa\": human_inform_backend_kappa\n",
    "\t\t\t},\n",
    "\t\t\t\"policy\": {\n",
    "\t\t\t\t\"gwet-ac1\": human_inform_policy_gwet,\n",
    "\t\t\t\t\"r_kappa\": human_inform_policy_kappa\n",
    "\t\t\t},\n",
    "\t\t\t\"overall\": {\n",
    "\t\t\t\t\"gwet-ac1\": overall_human_inform_gwet,\n",
    "\t\t\t\t\"r_kappa\": overall_human_inform_kappa\n",
    "\t\t\t},\n",
    "\t\t},\n",
    "\t\t\"mwoz-human-success\": {\n",
    "\t\t\t\"conv\": {\n",
    "\t\t\t\t\"gwet-ac1\": human_success_conv_gwet,\n",
    "\t\t\t\t\"r_kappa\": human_success_conv_kappa\n",
    "\t\t\t},\n",
    "\t\t\t\"backend\": {\n",
    "\t\t\t\t\"gwet-ac1\": human_success_backend_gwet,\n",
    "\t\t\t\t\"r_kappa\": human_success_backend_kappa\n",
    "\t\t\t},\n",
    "\t\t\t\"policy\": {\n",
    "\t\t\t\t\"gwet-ac1\": human_success_policy_gwet,\n",
    "\t\t\t\t\"r_kappa\": human_success_kappa\n",
    "\t\t\t},\n",
    "\t\t\t\"overall\": {\n",
    "\t\t\t\t\"gwet-ac1\": overall_human_success_gwet,\n",
    "\t\t\t\t\"r_kappa\": overall_human_success_kappa\n",
    "\t\t\t},\n",
    "\t\t},\n",
    "\t\t\"mwoz-human-trad-auto\": {\n",
    "\t\t\t\"conv\": {\n",
    "\t\t\t\t\"gwet-ac1\": human_trad_auto_conv_gwet,\n",
    "\t\t\t\t\"r_kappa\": human_trad_auto_conv_kappa\n",
    "\t\t\t},\n",
    "\t\t\t\"backend\": {\n",
    "\t\t\t\t\"gwet-ac1\": human_trad_auto_backend_gwet,\n",
    "\t\t\t\t\"r_kappa\": human_trad_auto_backend_kappa\n",
    "\t\t\t},\n",
    "\t\t\t\"policy\": {\n",
    "\t\t\t\t\"gwet-ac1\": human_trad_auto_policy_gwet,\n",
    "\t\t\t\t\"r_kappa\": human_trad_auto_policy_kappa\n",
    "\t\t\t},\n",
    "\t\t\t\"overall\": {\n",
    "\t\t\t\t\"gwet-ac1\": overall_human_trad_auto_gwet,\n",
    "\t\t\t\t\"r_kappa\": overall_human_trad_auto_kappa\n",
    "\t\t\t}\n",
    "\t\t}\n",
    "\t}\n",
    "\treturn dial_irr\n",
    "\n",
    "def compile_all_mwoz_scores_dial_level(\n",
    "\thuman_batch_scores: dict, \n",
    "\ttdeval_batch_scores: dict, \n",
    "\tlmunit_batch_scores: dict,\n",
    "\ttrad_batch_scores: dict,\n",
    "\ttrad_auto_scores: dict\n",
    "):\n",
    "\tdims = ['conv_consistency', 'backend_consistency', 'policy_completeness']\n",
    "\t# organize scores by batch\n",
    "\tbatch_human_scores = {}\n",
    "\tbatch_tdeval_scores = {}\n",
    "\tbatch_lmunit_scores = {}\n",
    "\tbatch_inform_scores = {}\n",
    "\tbatch_success_scores = {}\n",
    "\tbatch_trad_auto_scores = {}\n",
    "\t# consolidate scores into one large array\n",
    "\tall_human_scores = []\n",
    "\tall_tdeval_scores = []\n",
    "\tall_lmunit_scores = []\n",
    "\tall_inform_scores = []\n",
    "\tall_success_scores = []\n",
    "\tall_trad_auto_scores = []\n",
    "\tfor bId in human_batch_scores.keys():\n",
    "\t\thuman_dials = human_batch_scores[bId][\"dial_level\"]\n",
    "\t\ttdeval_dials = tdeval_batch_scores[bId][\"dial_level\"]\n",
    "\t\tlmunit_dials = lmunit_batch_scores[bId][\"dial_level\"]\n",
    "\t\ttrad_dials = trad_batch_scores[bId]\n",
    "\t\ttrad_auto_dials = trad_auto_scores[bId]\n",
    "\t\tbatch_human_scores[bId] = []\n",
    "\t\tbatch_tdeval_scores[bId] = []\n",
    "\t\tbatch_lmunit_scores[bId] = []\n",
    "\t\tbatch_inform_scores[bId] = []\n",
    "\t\tbatch_success_scores[bId] = []\n",
    "\t\tbatch_trad_auto_scores[bId] = []\n",
    "\t\tfor dId in human_dials.keys():\n",
    "\t\t\thuman_scores = human_dials[dId]\n",
    "\t\t\ttdeval_scores = tdeval_dials[dId]\n",
    "\t\t\tlmunit_score = lmunit_dials[dId]\n",
    "\t\t\ttrad_scores = trad_dials[dId]\n",
    "\t\t\ttrad_auto_score = trad_auto_dials[dId]\n",
    "\t\t\t# skip tau conversations \n",
    "\t\t\tif (\"airline\" in dId) or (\"retail\" in dId):\n",
    "\t\t\t\tcontinue\n",
    "\t\t\t# batch dial level is just a single score for the whole dialogue\n",
    "\t\t\tbatch_lmunit_scores[bId] = np.append(\n",
    "\t\t\t\tbatch_lmunit_scores[bId], \n",
    "\t\t\t\tlmunit_score\n",
    "\t\t\t)\n",
    "\t\t\tall_lmunit_scores = np.append(\n",
    "\t\t\t\tall_lmunit_scores, \n",
    "\t\t\t\tlmunit_score\n",
    "\t\t\t)\n",
    "\t\t\t# Inform/Success/Tau reward need to be concatenated differently\n",
    "\t\t\tbatch_inform_scores[bId] = np.append(\n",
    "\t\t\t\tbatch_inform_scores[bId], \n",
    "\t\t\t\ttrad_scores[\"inform\"]\n",
    "\t\t\t)\n",
    "\t\t\tall_inform_scores = np.append(\n",
    "\t\t\t\tall_inform_scores,\n",
    "\t\t\t\ttrad_scores[\"inform\"]\n",
    "\t\t\t)\n",
    "\t\t\tbatch_success_scores[bId] = np.append(\n",
    "\t\t\t\tbatch_success_scores[bId],\n",
    "\t\t\t\ttrad_scores[\"success\"]\n",
    "\t\t\t)\n",
    "\t\t\tall_success_scores = np.append(\n",
    "\t\t\t\tall_success_scores, \n",
    "\t\t\t\ttrad_scores[\"success\"]\n",
    "\t\t\t)\n",
    "\t\t\t# compile dialogue level automatic metrics, tau and mwoz are same format\n",
    "\t\t\tbatch_trad_auto_scores[bId] = np.append(\n",
    "\t\t\t\tbatch_trad_auto_scores[bId],\n",
    "\t\t\t\ttrad_auto_score\n",
    "\t\t\t)\n",
    "\t\t\tall_trad_auto_scores = np.append(\n",
    "\t\t\t\tall_trad_auto_scores,\n",
    "\t\t\t\ttrad_auto_score\n",
    "\t\t\t)\n",
    "\t\t\tfor metric in dims:\n",
    "\t\t\t\tbatch_human_scores[bId] = np.append(\n",
    "\t\t\t\t\tbatch_human_scores[bId], \n",
    "\t\t\t\t\thuman_scores[metric]\n",
    "\t\t\t\t)\n",
    "\t\t\t\tall_human_scores = np.append(\n",
    "\t\t\t\t\tall_human_scores, \n",
    "\t\t\t\t\thuman_scores[metric]\n",
    "\t\t\t\t)\n",
    "\t\t\t\tbatch_tdeval_scores[bId] = np.append(\n",
    "\t\t\t\t\tbatch_tdeval_scores[bId], \n",
    "\t\t\t\t\ttdeval_scores[metric]\n",
    "\t\t\t\t)\n",
    "\t\t\t\tall_tdeval_scores = np.append(\n",
    "\t\t\t\t\tall_tdeval_scores, \n",
    "\t\t\t\t\ttdeval_scores[metric]\n",
    "\t\t\t\t)\n",
    "\n",
    "\treturn {\n",
    "\t\t'batch': {\n",
    "\t\t\t'human': batch_human_scores,\n",
    "\t\t\t'tdeval': batch_tdeval_scores,\n",
    "\t\t\t'lmunit': batch_lmunit_scores,\n",
    "\t\t\t\"inform\": batch_inform_scores,\n",
    "\t\t\t\"success\": batch_success_scores,\n",
    "\t\t\t\"trad_auto\": batch_trad_auto_scores\n",
    "\t\t},\n",
    "\t\t\"all\": {\n",
    "\t\t\t'human': all_human_scores,\n",
    "\t\t\t'tdeval': all_tdeval_scores,\n",
    "\t\t\t'lmunit': all_lmunit_scores,\n",
    "\t\t\t\"inform\": all_inform_scores,\n",
    "\t\t\t\"success\": all_success_scores,\n",
    "\t\t\t\"trad_auto\": all_trad_auto_scores\n",
    "\t\t}\n",
    "\t}\n",
    "\n",
    "def calculate_mwoz_dial_level_agreement(\n",
    "\thuman_batch_scores: dict, \n",
    "\ttdeval_batch_scores: dict, \n",
    "\tlmunit_batch_scores: dict,\n",
    "\ttrad_batch_scores: dict,\n",
    "\ttrad_auto_batch_scores: dict\n",
    "):\n",
    "\tcompiled_scores = compile_all_mwoz_scores_dial_level(\t\n",
    "\t\thuman_batch_scores, \n",
    "\t\ttdeval_batch_scores, \n",
    "\t\tlmunit_batch_scores,\n",
    "\t\ttrad_batch_scores,\n",
    "\t\ttrad_auto_batch_scores\n",
    "\t)\n",
    "\t# serialize batched compile scores\n",
    "\tbatch_human_scores = compiled_scores['batch']['human']\n",
    "\tbatch_tdeval_scores = compiled_scores['batch']['tdeval']\n",
    "\tbatch_lmunit_scores = compiled_scores['batch']['lmunit']\n",
    "\tbatch_inform_scores = compiled_scores['batch']['inform']\n",
    "\tbatch_success_scores = compiled_scores['batch']['success']\n",
    "\tbatch_trad_auto_scores = compiled_scores['batch']['trad_auto']\n",
    "\t# serialized fully compiled scores\n",
    "\tall_human_scores = compiled_scores['all']['human']\n",
    "\tall_tdeval_scores = compiled_scores['all']['tdeval']\n",
    "\tall_lmunit_scores = compiled_scores['all']['lmunit']\n",
    "\tall_inform_scores = compiled_scores['all']['inform']\n",
    "\tall_success_scores = compiled_scores['all']['success']\n",
    "\tall_trad_auto_scores = compiled_scores['all']['trad_auto']\n",
    "\t# take IRR for each batch\n",
    "\tdial_irr = {}\n",
    "\tfor bId in human_batch_scores.keys():\n",
    "\t\tdial_irr[bId] = map_all_irr_mwoz_dial_level(\n",
    "\t\t\tbatch_human_scores[bId], \n",
    "\t\t\tbatch_tdeval_scores[bId], \n",
    "\t\t\tbatch_lmunit_scores[bId], \n",
    "\t\t\tbatch_inform_scores[bId], \n",
    "\t\t\tbatch_success_scores[bId],\n",
    "\t\t\tbatch_trad_auto_scores[bId]\n",
    "\t\t)\n",
    "\tdial_irr[\"all\"] = map_all_irr_mwoz_dial_level(\n",
    "\t\tall_human_scores,\n",
    "\t\tall_tdeval_scores,\n",
    "\t\tall_lmunit_scores,\n",
    "\t\tall_inform_scores,\n",
    "\t\tall_success_scores,\n",
    "\t\tall_trad_auto_scores\n",
    "\t)\n",
    "\treturn dial_irr\n",
    "\n",
    "mwoz_dial_level_irr = calculate_mwoz_dial_level_agreement(\n",
    "\thuman_batch_scores, \n",
    "\ttdeval_batch_scores, \n",
    "\tlmunit_batch_scores,\n",
    "\ttrad_batch_scores,\n",
    "\ttrad_auto_batch_scores\n",
    ")\n",
    "pprint.pprint(mwoz_dial_level_irr[\"all\"], compact=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a47e0fb3",
   "metadata": {},
   "source": [
    "#### Find agreement only on Tau dialogues using Reward metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef49a8cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_all_irr_tau_dial_level(\n",
    "\thuman_scores: np.ndarray, \n",
    "\ttdeval_scores: np.ndarray, \n",
    "\tlmunit_scores: np.ndarray, \n",
    "\treward_scores: np.ndarray, \n",
    "):\n",
    "\t# take IRR by metric (conv)\n",
    "\thuman_conv = human_scores[::3]\n",
    "\tbin_human_conv = np.where(human_conv >= 4, 1, 0)\n",
    "\ttdeval_conv = tdeval_scores[::3]\n",
    "\n",
    "\thuman_tdeval_conv = np.vstack(\n",
    "\t\t(human_conv, tdeval_conv)\n",
    "\t).astype(dtype=np.int64)\n",
    "\thuman_tdeval_conv_gwet = calculate_gwet_ac(human_tdeval_conv)\n",
    "\thuman_tdeval_conv_kappa = calculate_kappa(\n",
    "\t\thuman_tdeval_conv-1, \n",
    "\t\tn_cat=5\n",
    "\t)['randolph']\n",
    "\n",
    "\thuman_lmunit_conv = np.vstack(\n",
    "\t\t(human_conv, lmunit_scores)\n",
    "\t).astype(dtype=np.int64)\n",
    "\thuman_lmunit_conv_gwet = calculate_gwet_ac(human_lmunit_conv)\n",
    "\thuman_lmunit_conv_kappa = calculate_kappa(\n",
    "\t\thuman_lmunit_conv-1, \n",
    "\t\tn_cat=5\n",
    "\t)['randolph']\n",
    "\n",
    "\thuman_reward_conv = np.vstack(\n",
    "\t\t(bin_human_conv, reward_scores)\n",
    "\t).astype(dtype=np.int64)\n",
    "\thuman_reward_conv_gwet = calculate_gwet_ac(human_reward_conv)\n",
    "\thuman_reward_conv_kappa = calculate_kappa(\n",
    "\t\thuman_reward_conv, \n",
    "\t\tn_cat=2\n",
    "\t)['randolph']\n",
    "\n",
    "\t# take correlation by metric (backend)\n",
    "\thuman_backend = human_scores[1::3]\n",
    "\tbin_human_backend = np.where(human_backend >= 4, 1, 0)\n",
    "\ttdeval_backend = tdeval_scores[1::3]\n",
    "\thuman_tdeval_backend = np.vstack(\n",
    "\t\t(human_backend, tdeval_backend)\n",
    "\t).astype(dtype=np.int64)\n",
    "\thuman_tdeval_backend_gwet = calculate_gwet_ac(human_tdeval_backend)\n",
    "\thuman_tdeval_backend_kappa = calculate_kappa(\n",
    "\t\thuman_tdeval_backend-1, \n",
    "\t\tn_cat=5\n",
    "\t)['randolph']\n",
    "\n",
    "\thuman_lmunit_backend = np.vstack(\n",
    "\t\t(human_backend, lmunit_scores)\n",
    "\t).astype(dtype=np.int64)\n",
    "\thuman_lmunit_backend_gwet = calculate_gwet_ac(human_lmunit_backend)\n",
    "\thuman_lmunit_backend_kappa = calculate_kappa(\n",
    "\t\thuman_lmunit_backend-1, \n",
    "\t\tn_cat=5\n",
    "\t)['randolph']\n",
    "\n",
    "\thuman_reward_backend = np.vstack(\n",
    "\t\t(bin_human_backend, reward_scores)\n",
    "\t).astype(dtype=np.int64)\n",
    "\thuman_reward_backend_gwet = calculate_gwet_ac(\n",
    "\t\thuman_reward_backend\n",
    "\t)\n",
    "\thuman_reward_backend_kappa = calculate_kappa(\n",
    "\t\thuman_reward_backend, \n",
    "\t\tn_cat=2\n",
    "\t)['randolph']\n",
    "\n",
    "\t# take correlation by metric (policy)\n",
    "\thuman_policy = human_scores[2::3]\n",
    "\tbin_human_policy = np.where(human_policy >= 4, 1, 0)\n",
    "\ttdeval_policy = tdeval_scores[2::3]\n",
    "\t\n",
    "\thuman_tdeval_policy = np.vstack(\n",
    "\t\t(human_policy, tdeval_policy)\n",
    "\t).astype(dtype=np.int64)\n",
    "\thuman_tdeval_policy_gwet = calculate_gwet_ac(human_tdeval_policy)\n",
    "\thuman_tdeval_policy_kappa = calculate_kappa(\n",
    "\t\thuman_tdeval_policy-1, \n",
    "\t\tn_cat=5\n",
    "\t)['randolph']\n",
    "\n",
    "\thuman_lmunit_policy = np.vstack(\n",
    "\t\t(human_policy, lmunit_scores)\n",
    "\t).astype(dtype=np.int64)\n",
    "\thuman_lmunit_policy_gwet = calculate_gwet_ac(human_lmunit_policy)\n",
    "\thuman_lmunit_policy_kappa = calculate_kappa(\n",
    "\t\thuman_lmunit_policy-1, \n",
    "\t\tn_cat=5\n",
    "\t)['randolph']\n",
    "\n",
    "\thuman_reward_policy = np.vstack(\n",
    "\t\t(bin_human_policy, reward_scores)\n",
    "\t).astype(dtype=np.int64)\n",
    "\thuman_reward_policy_gwet = calculate_gwet_ac(\n",
    "\t\thuman_reward_policy\n",
    "\t)\n",
    "\thuman_reward_policy_kappa = calculate_kappa(\n",
    "\t\thuman_reward_policy, \n",
    "\t\tn_cat=2\n",
    "\t)['randolph']\n",
    "\n",
    "\t# take correlation of all metrics (overall)\n",
    "\toverall_human = human_scores\n",
    "\tavg_human = np.mean(human_scores.reshape((-1, 3)), axis=1)\n",
    "\tavg_bin_human = np.where(avg_human >= 4, 1, 0)\n",
    "\toverall_tdeval = tdeval_scores\n",
    "\n",
    "\toverall_human_tdeval = np.vstack(\n",
    "\t\t(overall_human, overall_tdeval)\n",
    "\t).astype(dtype=np.int64)\n",
    "\toverall_human_tdeval_gwet = calculate_gwet_ac(overall_human_tdeval)\n",
    "\toverall_human_tdeval_kappa = calculate_kappa(\n",
    "\t\toverall_human_tdeval-1, \n",
    "\t\t5\n",
    "\t)['randolph']\n",
    "\n",
    "\toverall_human_lmunit = np.vstack(\n",
    "\t\t(avg_human, lmunit_scores)\n",
    "\t).astype(dtype=np.int64)\n",
    "\toverall_human_lmunit_gwet = calculate_gwet_ac(overall_human_lmunit)\n",
    "\toverall_human_lmunit_kappa = calculate_kappa(\n",
    "\t\toverall_human_lmunit-1,\n",
    "\t\tn_cat=5\n",
    "\t)['randolph']\n",
    "\n",
    "\toverall_human_reward = np.vstack(\n",
    "\t\t(avg_bin_human, reward_scores)\n",
    "\t).astype(dtype=np.int64)\n",
    "\toverall_human_reward_gwet = calculate_gwet_ac(\n",
    "\t\toverall_human_reward\n",
    "\t)\n",
    "\toverall_human_reward_kappa = calculate_kappa(\n",
    "\t\toverall_human_reward, \n",
    "\t\tn_cat=2\n",
    "\t)['randolph']\n",
    "\n",
    "\tdial_irr = {\n",
    "\t\t\"tau-human-tdeval\": {\n",
    "\t\t\t\"conv\": {\n",
    "\t\t\t\t\"gwet-ac1\": human_tdeval_conv_gwet,\n",
    "\t\t\t\t\"r_kappa\": human_tdeval_conv_kappa\n",
    "\t\t\t}, \n",
    "\t\t\t\"backend\": {\n",
    "\t\t\t\t\"gwet-ac1\": human_tdeval_backend_gwet,\n",
    "\t\t\t\t\"r_kappa\": human_tdeval_backend_kappa\n",
    "\t\t\t},\n",
    "\t\t\t\"policy\": {\n",
    "\t\t\t\t\"gwet-ac1\": human_tdeval_policy_gwet,\n",
    "\t\t\t\t\"r_kappa\": human_tdeval_policy_kappa\n",
    "\t\t\t},\n",
    "\t\t\t\"overall\": {\n",
    "\t\t\t\t\"gwet-ac1\": overall_human_tdeval_gwet,\n",
    "\t\t\t\t\"r_kappa\": overall_human_tdeval_kappa\n",
    "\t\t\t},\n",
    "\t\t},\n",
    "\t\t\"tau-human-lmunit\": {\n",
    "\t\t\t\"conv\": {\n",
    "\t\t\t\t\"gwet-ac1\": human_lmunit_conv_gwet,\n",
    "\t\t\t\t\"r_kappa\": human_lmunit_conv_kappa\n",
    "\t\t\t},\n",
    "\t\t\t\"backend\": {\n",
    "\t\t\t\t\"gwet-ac1\": human_lmunit_backend_gwet,\n",
    "\t\t\t\t\"r_kappa\": human_lmunit_backend_kappa\n",
    "\t\t\t},\n",
    "\t\t\t\"policy\": {\n",
    "\t\t\t\t\"gwet-ac1\": human_lmunit_policy_gwet,\n",
    "\t\t\t\t\"r_kappa\": human_lmunit_policy_kappa\n",
    "\t\t\t},\n",
    "\t\t\t\"overall\": {\n",
    "\t\t\t\t\"gwet-ac1\": overall_human_lmunit_gwet,\n",
    "\t\t\t\t\"r_kappa\": overall_human_lmunit_kappa\n",
    "\t\t\t},\n",
    "\t\t},\n",
    "\t\t\"tau-human-reward\": {\n",
    "\t\t\t\"conv\": {\n",
    "\t\t\t\t\"gwet-ac1\": human_reward_conv_gwet,\n",
    "\t\t\t\t\"r_kappa\": human_reward_conv_kappa\n",
    "\t\t\t},\n",
    "\t\t\t\"backend\": {\n",
    "\t\t\t\t\"gwet-ac1\": human_reward_backend_gwet,\n",
    "\t\t\t\t\"r_kappa\": human_reward_backend_kappa\n",
    "\t\t\t},\n",
    "\t\t\t\"policy\": {\n",
    "\t\t\t\t\"gwet-ac1\": human_reward_policy_gwet,\n",
    "\t\t\t\t\"r_kappa\": human_reward_policy_kappa\n",
    "\t\t\t},\n",
    "\t\t\t\"overall\": {\n",
    "\t\t\t\t\"gwet-ac1\": overall_human_reward_gwet,\n",
    "\t\t\t\t\"r_kappa\": overall_human_reward_kappa\n",
    "\t\t\t},\n",
    "\t\t}\n",
    "\t}\n",
    "\treturn dial_irr\n",
    "\n",
    "def compile_all_tau_scores_dial_level(\n",
    "\thuman_batch_scores: dict, \n",
    "\ttdeval_batch_scores: dict, \n",
    "\tlmunit_batch_scores: dict,\n",
    "\ttrad_batch_scores: dict,\n",
    "):\n",
    "\tdims = ['conv_consistency', 'backend_consistency', 'policy_completeness']\n",
    "\t# organize scores by batch\n",
    "\tbatch_human_scores = {}\n",
    "\tbatch_tdeval_scores = {}\n",
    "\tbatch_lmunit_scores = {}\n",
    "\tbatch_reward_scores = {}\n",
    "\t# consolidate scores into one large array\n",
    "\tall_human_scores = []\n",
    "\tall_tdeval_scores = []\n",
    "\tall_lmunit_scores = []\n",
    "\tall_reward_scores = []\n",
    "\tfor bId in human_batch_scores.keys():\n",
    "\t\thuman_dials = human_batch_scores[bId][\"dial_level\"]\n",
    "\t\ttdeval_dials = tdeval_batch_scores[bId][\"dial_level\"]\n",
    "\t\tlmunit_dials = lmunit_batch_scores[bId][\"dial_level\"]\n",
    "\t\ttrad_dials = trad_batch_scores[bId]\n",
    "\t\tbatch_human_scores[bId] = []\n",
    "\t\tbatch_tdeval_scores[bId] = []\n",
    "\t\tbatch_lmunit_scores[bId] = []\n",
    "\t\tbatch_reward_scores[bId] = []\n",
    "\t\tfor dId in human_dials.keys():\n",
    "\t\t\thuman_scores = human_dials[dId]\n",
    "\t\t\ttdeval_scores = tdeval_dials[dId]\n",
    "\t\t\tlmunit_score = lmunit_dials[dId]\n",
    "\t\t\ttrad_scores = trad_dials[dId]\n",
    "\t\t\t# skip mwoz conversations \n",
    "\t\t\tif (\"airline\" not in dId) and (\"retail\" not in dId):\n",
    "\t\t\t\tcontinue\n",
    "\t\t\tbatch_lmunit_scores[bId] = np.append(\n",
    "\t\t\t\tbatch_lmunit_scores[bId], \n",
    "\t\t\t\tlmunit_score\n",
    "\t\t\t)\n",
    "\t\t\tall_lmunit_scores = np.append(\n",
    "\t\t\t\tall_lmunit_scores, \n",
    "\t\t\t\tlmunit_score\n",
    "\t\t\t)\n",
    "\t\t\t# Inform/Success/Tau reward need to be concatenated differently\n",
    "\t\t\tbatch_reward_scores[bId] = np.append(\n",
    "\t\t\t\tbatch_reward_scores[bId], \n",
    "\t\t\t\ttrad_scores\n",
    "\t\t\t)\n",
    "\t\t\tall_reward_scores = np.append(\n",
    "\t\t\t\tall_reward_scores,\n",
    "\t\t\t\ttrad_scores\n",
    "\t\t\t)\n",
    "\t\t\tfor metric in dims:\n",
    "\t\t\t\tbatch_human_scores[bId] = np.append(\n",
    "\t\t\t\t\tbatch_human_scores[bId], \n",
    "\t\t\t\t\thuman_scores[metric]\n",
    "\t\t\t\t)\n",
    "\t\t\t\tall_human_scores = np.append(\n",
    "\t\t\t\t\tall_human_scores, \n",
    "\t\t\t\t\thuman_scores[metric]\n",
    "\t\t\t\t)\n",
    "\t\t\t\tbatch_tdeval_scores[bId] = np.append(\n",
    "\t\t\t\t\tbatch_tdeval_scores[bId], \n",
    "\t\t\t\t\ttdeval_scores[metric]\n",
    "\t\t\t\t)\n",
    "\t\t\t\tall_tdeval_scores = np.append(\n",
    "\t\t\t\t\tall_tdeval_scores, \n",
    "\t\t\t\t\ttdeval_scores[metric]\n",
    "\t\t\t\t)\n",
    "\treturn {\n",
    "\t\t'batch': {\n",
    "\t\t\t'human': batch_human_scores,\n",
    "\t\t\t'tdeval': batch_tdeval_scores,\n",
    "\t\t\t'lmunit': batch_lmunit_scores,\n",
    "\t\t\t\"reward\": batch_reward_scores,\n",
    "\t\t},\n",
    "\t\t\"all\": {\n",
    "\t\t\t'human': all_human_scores,\n",
    "\t\t\t'tdeval': all_tdeval_scores,\n",
    "\t\t\t'lmunit': all_lmunit_scores,\n",
    "\t\t\t\"reward\": all_reward_scores,\n",
    "\t\t}\n",
    "\t}\n",
    "\n",
    "def calculate_tau_dial_level_agreement(\n",
    "\thuman_batch_scores: dict, \n",
    "\ttdeval_batch_scores: dict, \n",
    "\tlmunit_batch_scores: dict,\n",
    "\ttrad_batch_scores: dict,\n",
    "):\n",
    "\tcompiled_scores = compile_all_tau_scores_dial_level(\t\n",
    "\t\thuman_batch_scores, \n",
    "\t\ttdeval_batch_scores, \n",
    "\t\tlmunit_batch_scores,\n",
    "\t\ttrad_batch_scores,\n",
    "\t)\n",
    "\t# serialize batched compile scores\n",
    "\tbatch_human_scores = compiled_scores['batch']['human']\n",
    "\tbatch_tdeval_scores = compiled_scores['batch']['tdeval']\n",
    "\tbatch_lmunit_scores = compiled_scores['batch']['lmunit']\n",
    "\tbatch_reward_scores = compiled_scores['batch']['reward']\n",
    "\t# serialized fully compiled scores\n",
    "\tall_human_scores = compiled_scores['all']['human']\n",
    "\tall_tdeval_scores = compiled_scores['all']['tdeval']\n",
    "\tall_lmunit_scores = compiled_scores['all']['lmunit']\n",
    "\tall_reward_scores = compiled_scores['all']['reward']\n",
    "\t# take IRR for each batch\n",
    "\tdial_irr = {}\n",
    "\tfor bId in human_batch_scores.keys():\n",
    "\t\tdial_irr[bId] = map_all_irr_tau_dial_level(\n",
    "\t\t\tbatch_human_scores[bId], \n",
    "\t\t\tbatch_tdeval_scores[bId], \n",
    "\t\t\tbatch_lmunit_scores[bId], \n",
    "\t\t\tbatch_reward_scores[bId],\n",
    "\t\t)\n",
    "\tdial_irr[\"all\"] = map_all_irr_tau_dial_level(\n",
    "\t\tall_human_scores,\n",
    "\t\tall_tdeval_scores,\n",
    "\t\tall_lmunit_scores,\n",
    "\t\tall_reward_scores,\n",
    "\t)\n",
    "\treturn dial_irr\n",
    "\n",
    "tau_dial_level_irr = calculate_tau_dial_level_agreement(\n",
    "\thuman_batch_scores, \n",
    "\ttdeval_batch_scores, \n",
    "\tlmunit_batch_scores,\n",
    "\ttrad_batch_scores\n",
    ")\n",
    "pprint.pprint(tau_dial_level_irr[\"all\"], compact=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04aa1e41",
   "metadata": {},
   "source": [
    "### Compile Results and Save to File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e553470",
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison_results = {\n",
    "\t'turn_level_corrs': turn_level_corr[\"all\"],\n",
    "\t'turn_level_irr': turn_level_irr[\"all\"],\n",
    "\t'dial_level_corrs': dial_level_corr[\"all\"],\n",
    "\t'dial_level_irr': dial_level_irr[\"all\"],\n",
    "\t'mwoz_dial_level_irr': mwoz_dial_level_irr[\"all\"]\n",
    "}\n",
    "output_dir = \"agreement_scores\"\n",
    "with open(os.path.join(output_dir, 'main_human_eval.json'), 'w') as f:\n",
    "\tjson.dump(comparison_results, f, indent=4)    \n",
    "print(f\"\\nResults saved to {output_dir}\")"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "turn-eval",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
