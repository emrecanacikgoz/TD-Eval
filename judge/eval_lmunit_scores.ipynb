{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "from time import sleep\n",
    "from postprocess import extract_score\n",
    "import scipy.stats as stats\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "\n",
    "url = \"https://api.contextual.ai/v1/lmunit\"\n",
    "\n",
    "headers = {\n",
    "\t\"accept\": \"application/json\",\n",
    "\t\"content-type\": \"application/json\",\n",
    "\t\"authorization\": \"Bearer key-CLRoggUEDxqJn3DHU6hPHk3R5f6KL98IEgDBpISri1Iwp8ptg\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set Model and File Locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dials = {\n",
    "  \"autotod_mwoz_eval_json\": \"../judge/results/judge_results_lmunit/autotod/mwoz-autotod-lmunit_j.json\",\n",
    "\t\"tau_retail_eval_json\": \"../judge/results/judge-results-tau/20250131_152422-tau-4o-retail/tau-gpt-4o_j.json\",\n",
    "\t\"tau_air_eval_json\": \"../judge/results/judge-results-tau/20250131_152503-tau-4o-airline/tau-gpt-4o_j.json\",\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load and Filter Dialogue Data For Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_filter_dials(\n",
    "\tautotod_mwoz_eval_json: str,\n",
    "\ttau_retail_eval_json: str, \n",
    "\ttau_air_eval_json: str,\n",
    "\tbatch_json_path: str):\n",
    "\n",
    "\tfor p in (tau_retail_eval_json, tau_air_eval_json, batch_json_path):\n",
    "\t\tif not os.path.exists(p):\n",
    "\t\t\t\traise FileNotFoundError(f\"Couldn't find {p!r}\")\n",
    "\t\t\n",
    "\twith open(autotod_mwoz_eval_json, 'r') as f:\n",
    "\t\tmwoz_dials = json.load(f)['dialogues']\n",
    "\twith open(tau_retail_eval_json, 'r', encoding='utf-8') as f:\n",
    "\t\ttau_retail_dials = json.load(f)['dialogues']\n",
    "\twith open(tau_air_eval_json, 'r', encoding='utf-8') as f:\n",
    "\t\ttau_air_dials    = json.load(f)['dialogues']\n",
    "\n",
    "\twith open(batch_json_path, 'r', encoding='utf-8') as f:\n",
    "\t\tbatch_list = json.load(f)\n",
    "\tbatch_dials = {}\n",
    "\tfor bid in batch_list['autotod_mwoz']:\n",
    "\t\tmwoz_bid = bid.upper() + \".json\"\n",
    "\t\tif mwoz_bid in mwoz_dials:\n",
    "\t\t\t\tbatch_dials[bid] = mwoz_dials[mwoz_bid]\n",
    "\tfor bid in batch_list[\"tau\"][\"retail\"]:\n",
    "\t\tif bid in tau_retail_dials:\n",
    "\t\t\tbatch_dials[f\"retail_{bid}\"] = tau_retail_dials[bid]\n",
    "\tfor bid in batch_list[\"tau\"][\"airline\"]:\n",
    "\t\tif bid in tau_air_dials:\n",
    "\t\t\tbatch_dials[f\"airline_{bid}\"] = tau_air_dials[bid]\n",
    "\treturn batch_dials"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate LMUnit Score on Dialogues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_qs = [\n",
    "\t\"Does the response directly relate to the dialogue history and the current user query?\",\n",
    "\t\"Does the response remain on-topic with the dialogue history and the user query?\",\n",
    "\t\"Does the response logically continue the progression of the dialogue?\"\n",
    "]\n",
    "backend_qs = [\n",
    "\t\"Does the response accurately reflect the information in the database results?\",\n",
    "\t\"Does the response stay on-topic with the database results and the dialogue context?\",\n",
    "\t\"Does response logically incorporate and progress based on the database results?\"\n",
    "]\n",
    "policy_qs = [\n",
    "\t\"Does the response provide suggestions only when the database results are few enough to do so?\",\n",
    "\t\"Does the response request required, relevant information from the user before offering suggestions or booking services?\",\n",
    "\t\"Does the response avoid premature actions (i.e. make a booking or suggest a service) too early in the conversation, before the necessary information is gathered?\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_dials_lmunit(batch_dials):\n",
    "\t\"\"\"Run each turn through the LMâ€‘unit API with retry logic for rate limits.\"\"\"\n",
    "\timport time\n",
    "\timport random\n",
    "\t\n",
    "\tlmunit_scores = {}\n",
    "\tfor dial_id, turns in batch_dials.items():\n",
    "\t\tprint(f\"Processing dialogue {dial_id}...\")\n",
    "\t\tlmunit_scores[dial_id] = []\n",
    "\t\t\n",
    "\t\tfor turn_idx, turn in enumerate(turns):\n",
    "\t\t\tprint(f\"  Turn {turn_idx+1}/{len(turns)}\")\n",
    "\t\t\thistory = turn[\"conversation_history\"] + \"\\nCustomer: \" + turn[\"user\"]\n",
    "\t\t\tresponse = turn.get(\"lex_response\", turn.get(\"response\", \"\"))\n",
    "\t\t\tdb_content = json.dumps(turn.get(\"db\", {}))\n",
    "\n",
    "\t\t\tdef make_api_call(payload, max_retries=5):\n",
    "\t\t\t\tretries = 0\n",
    "\t\t\t\twhile retries < max_retries:\n",
    "\t\t\t\t\ttry:\n",
    "\t\t\t\t\t\tr = requests.post(url, json=payload, headers=headers)\n",
    "\t\t\t\t\t\tdata = r.json()\n",
    "\t\t\t\t\t\t\n",
    "\t\t\t\t\t\tif \"score\" in data:\n",
    "\t\t\t\t\t\t\treturn float(data[\"score\"])\n",
    "\t\t\t\t\t\telif \"detail\" in data and \"Too Many Requests\" in str(data[\"detail\"]):\n",
    "\t\t\t\t\t\t\tretry_seconds = 1\n",
    "\t\t\t\t\t\t\tif isinstance(data[\"detail\"], str) and \"Retry after\" in data[\"detail\"]:\n",
    "\t\t\t\t\t\t\t\t\ttry:\n",
    "\t\t\t\t\t\t\t\t\t\t\tretry_seconds = int(data[\"detail\"].split(\"Retry after\")[1].split(\"seconds\")[0].strip())\n",
    "\t\t\t\t\t\t\t\t\texcept:\n",
    "\t\t\t\t\t\t\t\t\t\t\tpass\n",
    "\t\t\t\t\t\t\t\n",
    "\t\t\t\t\t\t\tsleep_time = retry_seconds + random.uniform(0.1, 1.0)\n",
    "\t\t\t\t\t\t\tprint(f\"    Rate limited. Sleeping for {sleep_time:.2f}s (retry {retries+1}/{max_retries})\")\n",
    "\t\t\t\t\t\t\ttime.sleep(sleep_time)\n",
    "\t\t\t\t\t\t\tretries += 1\n",
    "\t\t\t\t\t\telse:\n",
    "\t\t\t\t\t\t\tprint(f\"    Error in API response: {data}\")\n",
    "\t\t\t\t\t\t\treturn 0.0\n",
    "\t\t\t\t\texcept Exception as e:\n",
    "\t\t\t\t\t\tprint(f\"    Exception during API call: {e}\")\n",
    "\t\t\t\t\t\ttime.sleep(2)\n",
    "\t\t\t\t\t\tretries += 1\n",
    "\t\t\t\t\n",
    "\t\t\t\tprint(f\"    Maximum retries reached for API call.\")\n",
    "\t\t\t\treturn 0.0\n",
    "\t\t\t\n",
    "\t\t\t#conversation consistency\n",
    "\t\t\tconv_scores = []\n",
    "\t\t\tfor q in conv_qs:\n",
    "\t\t\t\tpayload = {\"query\": history, \"response\": response, \"unit_test\": q}\n",
    "\t\t\t\tscore = make_api_call(payload)\n",
    "\t\t\t\tconv_scores.append(score)\n",
    "\t\t\t\ttime.sleep(0.5)  #delay \n",
    "\t\t\tconv_score = sum(conv_scores) / len(conv_scores) if conv_scores else 0\n",
    "\t\t\t\n",
    "\t\t\t# backend knowledge consistency - FIX THE PAYLOAD FORMAT\n",
    "\t\t\tbackend_scores = []\n",
    "\t\t\tfor q in backend_qs:\n",
    "\t\t\t\tpayload = {\n",
    "\t\t\t\t\t\"query\": f\"{history}\\nDatabase result: {db_content}\",\n",
    "\t\t\t\t\t\"response\": response,\n",
    "\t\t\t\t\t\"unit_test\": q\n",
    "\t\t\t\t}\n",
    "\t\t\t\tscore = make_api_call(payload)\n",
    "\t\t\t\tbackend_scores.append(score)\n",
    "\t\t\t\ttime.sleep(0.5)\n",
    "\t\t\tbackend_score = sum(backend_scores) / len(backend_scores) if backend_scores else 0\n",
    "\t\t\t\n",
    "\t\t\t#policy compliance\n",
    "\t\t\tpolicy_scores = []\n",
    "\t\t\tfor q in policy_qs:\n",
    "\t\t\t\tpayload = {\n",
    "\t\t\t\t\t\"query\": f\"{history}\\nDatabase result: {db_content}\",\n",
    "\t\t\t\t\t\"response\": response,\n",
    "\t\t\t\t\t\"unit_test\": q\n",
    "\t\t\t\t}\n",
    "\t\t\t\tscore = make_api_call(payload)\n",
    "\t\t\t\tpolicy_scores.append(score)\n",
    "\t\t\t\ttime.sleep(0.5)\n",
    "\t\t\tpolicy_score = sum(policy_scores) / len(policy_scores) if policy_scores else 0\n",
    "\t\t\t\n",
    "\t\t\t# compile scores\n",
    "\t\t\tlmunit_scores[dial_id].append({\n",
    "\t\t\t\t\"conv_consistency\": round(conv_score, 2),\n",
    "\t\t\t\t\"backend_consistency\": round(backend_score, 2),\n",
    "\t\t\t\t\"policy_completeness\": round(policy_score, 2)\n",
    "\t\t\t})\n",
    "\t\t\t\n",
    "\t\t\t# Print current scores summary\n",
    "\t\t\tprint(f\"    Scores - Conv: {round(conv_score, 2)}, Backend: {round(backend_score, 2)}, Policy: {round(policy_score, 2)}\")\n",
    "\t\t\t# Longer pause between turns\n",
    "\t\t\ttime.sleep(3)\n",
    "\t\t\n",
    "\t\t# Pause between dialogues\n",
    "\t\ttime.sleep(5)\n",
    "\t\n",
    "\treturn lmunit_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dialogue Level Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dial_level_q = \"Does the conversation successfully achieve its intended goal?\"\n",
    "\n",
    "goal_files = {\n",
    "  \"autotod_mwoz_json\": \"../datasets/autotod_dials_fm_eval.json\",\n",
    "\t\"tau_retail_json\": \"../judge/results/agent-results-tau/tool-calling-gpt-4o-0.0_range_0--1_user-gpt-4o-llm_0114161231-retail.json\",\n",
    "\t\"tau_air_json\": \"../judge/results/agent-results-tau/tool-calling-gpt-4o-0.0_range_0--1_user-gpt-4o-llm_0114160308-airline.json\",\n",
    "}\n",
    "\n",
    "def load_filter_dial_goals(\n",
    "\tautotod_mwoz_goal_json: str,\n",
    "\ttau_retail_goal_json: str, \n",
    "\ttau_air_goal_json: str,\n",
    "\tbatch_json_path: str):\n",
    "\n",
    "\tfor p in (tau_retail_goal_json, tau_air_goal_json, batch_json_path):\n",
    "\t\tif not os.path.exists(p):\n",
    "\t\t\t\traise FileNotFoundError(f\"Couldn't find {p!r}\")\n",
    "\t\t\n",
    "\twith open(autotod_mwoz_goal_json, 'r') as f:\n",
    "\t\tmwoz_dials = json.load(f)\n",
    "\twith open(tau_retail_goal_json, 'r', encoding='utf-8') as f:\n",
    "\t\ttau_retail_dials = json.load(f)\n",
    "\twith open(tau_air_goal_json, 'r', encoding='utf-8') as f:\n",
    "\t\ttau_air_dials = json.load(f)\n",
    "\n",
    "\twith open(batch_json_path, 'r', encoding='utf-8') as f:\n",
    "\t\tbatch_list = json.load(f)\n",
    "\tbatch_goals = {}\n",
    "\tfor bid in batch_list['autotod_mwoz']:\n",
    "\t\tmwoz_bid = bid.upper() + \".json\"\n",
    "\t\tif mwoz_bid in mwoz_dials:\n",
    "\t\t\t\tgoal = \"\\n\".join(mwoz_dials[mwoz_bid][\"run_result\"][\"goal_messages\"])\n",
    "\t\t\t\t# print(\"goal:\", goal)\n",
    "\t\t\t\tbatch_goals[bid] = goal\n",
    "\tfor bid in batch_list[\"tau\"][\"retail\"]:\n",
    "\t\t# if bid in tau_retail_dials:\n",
    "\t\tgoal = tau_retail_dials[int(bid)][\"info\"][\"task\"][\"instruction\"]\n",
    "\t\tbatch_goals[f\"retail_{bid}\"] = goal\n",
    "\tfor bid in batch_list[\"tau\"][\"airline\"]:\n",
    "\t\t# if bid in tau_air_dials:\n",
    "\t\tgoal = tau_air_dials[int(bid)][\"info\"][\"task\"][\"instruction\"]\n",
    "\t\tbatch_goals[f\"airline_{bid}\"] = goal\n",
    "\treturn batch_goals\n",
    "\n",
    "def eval_dial_level_lmunit(batch_dials, dial_goals):\n",
    "\t\"\"\"Run each turn through the LMâ€‘unit API with retry logic for rate limits.\"\"\"\n",
    "\timport time\n",
    "\timport random\n",
    "\t\n",
    "\tlmunit_scores = {}\n",
    "\tfor dial_id, turns in batch_dials.items():\n",
    "\t\tprint(f\"Processing dialogue {dial_id}...\")\n",
    "\n",
    "\t\tdef make_api_call(payload, max_retries=5):\n",
    "\t\t\tretries = 0\n",
    "\t\t\twhile retries < max_retries:\n",
    "\t\t\t\ttry:\n",
    "\t\t\t\t\tr = requests.post(url, json=payload, headers=headers)\n",
    "\t\t\t\t\tdata = r.json()\n",
    "\t\t\t\t\t\n",
    "\t\t\t\t\tif \"score\" in data:\n",
    "\t\t\t\t\t\treturn float(data[\"score\"])\n",
    "\t\t\t\t\telif \"detail\" in data and \"Too Many Requests\" in str(data[\"detail\"]):\n",
    "\t\t\t\t\t\tretry_seconds = 1\n",
    "\t\t\t\t\t\tif isinstance(data[\"detail\"], str) and \"Retry after\" in data[\"detail\"]:\n",
    "\t\t\t\t\t\t\t\ttry:\n",
    "\t\t\t\t\t\t\t\t\t\tretry_seconds = int(data[\"detail\"].split(\"Retry after\")[1].split(\"seconds\")[0].strip())\n",
    "\t\t\t\t\t\t\t\texcept:\n",
    "\t\t\t\t\t\t\t\t\t\tpass\n",
    "\t\t\t\t\t\t\n",
    "\t\t\t\t\t\tsleep_time = retry_seconds + random.uniform(0.1, 1.0)\n",
    "\t\t\t\t\t\tprint(f\"    Rate limited. Sleeping for {sleep_time:.2f}s (retry {retries+1}/{max_retries})\")\n",
    "\t\t\t\t\t\ttime.sleep(sleep_time)\n",
    "\t\t\t\t\t\tretries += 1\n",
    "\t\t\t\t\telse:\n",
    "\t\t\t\t\t\tprint(f\"    Error in API response: {data}\")\n",
    "\t\t\t\t\t\treturn 0.0\n",
    "\t\t\t\texcept Exception as e:\n",
    "\t\t\t\t\tprint(f\"    Exception during API call: {e}\")\n",
    "\t\t\t\t\ttime.sleep(2)\n",
    "\t\t\t\t\tretries += 1\n",
    "\t\t\t\n",
    "\t\t\tprint(f\"    Maximum retries reached for API call.\")\n",
    "\t\t\treturn 0.0\n",
    "\t\t\n",
    "\t\tconv_hist = \"\"\n",
    "\t\tfor turn in turns:\n",
    "\t\t\tquery = turn[\"user\"]\n",
    "\t\t\tresponse = turn.get(\"lex_response\", turn.get(\"response\", \"\"))\n",
    "\t\t\tconv_hist += f\"Customer: {query}\\nResponse: {response}\\n\"\n",
    "\t\t\t\n",
    "\t\t# dialogue level goal score\n",
    "\t\tgoal = dial_goals[dial_id]\n",
    "\t\tpayload = {\n",
    "\t\t\t\"query\": f\"Goal: {goal}\", \n",
    "\t\t\t\"response\": conv_hist, \n",
    "\t\t\t\"unit_test\": dial_level_q\n",
    "\t\t}\n",
    "\t\tdial_level_score = make_api_call(payload)\n",
    "\t\ttime.sleep(0.5)  #delay \n",
    "\t\n",
    "\t\t# compile scores\n",
    "\t\tlmunit_scores[dial_id] = round(dial_level_score, 2)\n",
    "\t\t\n",
    "\t\t# Print current scores summary\n",
    "\t\tprint(f\"Scores - Dialog Level: {round(dial_level_score, 2)}\")\n",
    "\t\t# Longer pause between turns\n",
    "\t\ttime.sleep(3)\n",
    "\t\t\n",
    "\t\t# Pause between dialogues\n",
    "\t\ttime.sleep(3)\n",
    "\t\n",
    "\treturn lmunit_scores\n",
    "\n",
    "# Display the results\n",
    "batch_path = \"../datasets/main_human_eval/all_batch.json\"\n",
    "filtered_dials = load_filter_dials(\n",
    "\tdials[\"autotod_mwoz_eval_json\"],\n",
    "\tdials[\"tau_retail_eval_json\"],\n",
    "\tdials[\"tau_air_eval_json\"],\n",
    "\tbatch_path\n",
    ")\n",
    "\n",
    "filtered_goals = load_filter_dial_goals(\n",
    "\tgoal_files[\"autotod_mwoz_json\"],\n",
    "\tgoal_files[\"tau_retail_json\"],\n",
    "\tgoal_files[\"tau_air_json\"],\n",
    "\tbatch_path\n",
    ")\n",
    "\n",
    "real_results = eval_dial_level_lmunit(filtered_dials, filtered_goals)\n",
    "\n",
    "# save results to file\n",
    "with open(\"lmunit_dial_scores.json\", \"w\") as f:\n",
    "    json.dump(real_results, f, indent=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, HTML\n",
    "import pandas as pd\n",
    "\n",
    "def display_scores(scores_dict, show_averages=True):\n",
    "\t\"\"\"Display evaluation scores in a nice format.\"\"\"\n",
    "\trows = []\n",
    "\tfor dial_id, turns in scores_dict.items():\n",
    "\t\tfor turn_idx, scores in enumerate(turns):\n",
    "\t\t\trow = {\n",
    "\t\t\t\t\"Dialogue ID\": dial_id,\n",
    "\t\t\t\t\"Turn\": turn_idx + 1,\n",
    "\t\t\t\t\"Conversation Consistency\": scores[\"conv_consistency\"],\n",
    "\t\t\t\t\"Backend Consistency\": scores[\"backend_consistency\"],\n",
    "\t\t\t\t\"Policy Completeness\": scores[\"policy_completeness\"],\n",
    "\t\t\t\t\"Average Score\": round((scores[\"conv_consistency\"] + \n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tscores[\"backend_consistency\"] + \n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tscores[\"policy_completeness\"])/3, 2)\n",
    "\t\t\t}\n",
    "\t\t\trows.append(row)\n",
    "\n",
    "\n",
    "\tdf = pd.DataFrame(rows)\n",
    "\t\n",
    "\t# Overall statistics\n",
    "\tif show_averages and len(df) > 0:\n",
    "\t\tdisplay(HTML(\"<h3>LMUnit Evaluation Results</h3>\"))\n",
    "\t\tdisplay(df)\n",
    "\t\t\n",
    "\t\tdisplay(HTML(\"<h3>Summary Statistics</h3>\"))\n",
    "\t\tsummary_df = df.groupby(\"Dialogue ID\")[\n",
    "\t\t\t[\"Conversation Consistency\", \"Backend Consistency\", \n",
    "\t\t\t\t\"Policy Completeness\", \"Average Score\"]\n",
    "\t\t].mean().round(2)\n",
    "\t\t\n",
    "\t\t# Add overall average row\n",
    "\t\toverall_avg = summary_df.mean().round(2)\n",
    "\t\tsummary_df.loc[\"OVERALL\"] = overall_avg\n",
    "\t\t\n",
    "\t\tdisplay(summary_df)\n",
    "\telse:\n",
    "\t\tdisplay(df)\n",
    "\t\n",
    "\treturn df\n",
    "\n",
    "# Display the results\n",
    "batch_path = \"../datasets/main_human_eval/all_batch.json\"\n",
    "filtered_dials = load_filter_dials(\n",
    "    dials[\"tau_retail_eval_json\"],\n",
    "    dials[\"tau_air_eval_json\"],\n",
    "    batch_path\n",
    ")\n",
    "\n",
    "real_results = eval_dials_lmunit(filtered_dials)\n",
    "\n",
    "# save results to file\n",
    "with open(\"results/judge_results_lmunit/lmunit_scores.json\", \"w\") as f:\n",
    "    json.dump(real_results, f, indent=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "turn-eval",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
